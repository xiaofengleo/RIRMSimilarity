easily discover data stored in the myocean environment generic information about iagos the in service aircraft for global observing system
iagos is european research infrastructure which implements and operates global observation system for atmospheric composition by deploying autonomous instruments aboard
fleet of commercial passenger aircraft it conducts long term observations of atmospheric composition aerosol and cloud particles on global scale41
iagos provides freely accessible data for users in science and policy including air quality forecasting verification of co2 emissions and
kyoto monitoring numerical weather prediction and validation of satellite products iagos expects through its participation in envriplus to improve data
discovery metadata standardisation interoperability citation and doi management it also expects envriplus to provide services for citation cataloguing and provenance
generic information about icos the integrated carbon observation system icos research infrastructure provides the long term observations required to understand
the present state and predict future behaviour of the global carbon cycle and greenhouse gas emissions and concentrations42 the objectives
of icos are to provide effective access to single and coherent data set to facilitate research into multi scale analysis
of greenhouse gas emissions sinks and the processes that determine them and to provide information which is profound for research
and for the understanding of regional budgets of greenhouse gas sources and sinks their human and natural drivers and the
controlling mechanisms icos expects envriplus to provide access to tools and services in the fields of metadata curation including recipes
for cataloguing and storage data object identification and citation collection and handling of provenance information generic information about interact the
international network for terrestrial research and monitoring in the arctic interact is circumarctic network of terrestrial field stations in northern
europe russia usa canada greenland iceland the faroe islands and scotland interact main objective is to build capacity for identifying
understanding predicting and responding to diverse environmental changes throughout the wide environmental and land use envelopes of the arctic together
the interact stations host many thousands of scientists from around the world working in multiple disciplines and interact collaborates with
many research consortia and international research and monitoring networks43 interact is keen on working on homogenisation with other infrastructures the
most important bilateral benefits of nordgis the interact geographical metadata information system44 versus envriplus are the broad european standards exposed
to nordgis as well as the grass root requirements exposed to envriplus interact is open for new interactive solutions and
recognises that standards on how to turn primary data into data products suitable for open dissemination need to be adopted
generic information about is enes2 the european network for earth system modelling is enes2 is the second phase of the
i3 infrastructure project for the european network for earth system modelling enes enes gathers the community working on climate modelling
is enes runs distributed federated data infrastructure based on few main data centres and various associated smaller ones45 is enes
encompasses climate models and their environment tools model data and the interface of the climate modelling community with high performance
computing in particular the european ri prace the requirements information provided to envriplus refers to the climate modelling community to
two data dissemination systems esgf for project run time lta as long term archiving to cmip5 as climate modelling data
project and cmip6 by participating in envriplus is enes2 expects to obtain better understanding of interdisciplinary use cases and end
user requirements as well as advice for data catalogues to compare their model data with other data observations generic information
about lter long term ecosystem research lter is an essential component of worldwide efforts to better understand ecosystems this comprises
their structure functions and long term response to environmental societal and economic drivers lter contributes to the knowledge base informing
policy and to the development of management options in response to the grand challenges under global change46 from the beginning
around the design of lter europe has focused on the integration of natural sciences and ecosystem research approaches including the
human dimension lter europe was heavily involved in conceptualising socio ecological research ltser as well as lter sites lter europe
features ltser platforms acting as test infrastructures for new generation of ecosystem research across european environmental and socio economic gradients
lter europe aims at providing information on ecosystem functioning and processes as well as related drivers and pressures for whole
ecosystem watershed this information is very diverse in its technical formats sensor information aerial photographs field recordings pictures etc the
purpose of the ri is to focus on harmonised methodologies and data products due to the fragmented character of lter
europe harmonised data documentation real time availability of data as well as harmonisation of data and data flows are the
overarching goals for the forthcoming years currently lter europe is developing data integration portal dip including time series viewer and
is working on the integration of common data repositories into their workflow system including metadata documentation with lter europe deims47
therefore based on the common reference model envriplus can provide development advice on those matters which would be appreciated by
lter generic information about seadatanet seadatanet is pan european infrastructure for ocean marine data management which provides on line integrated
databases of standardised quality it develops an efficient distributed marine data management infrastructure for managing large and diverse data sets
deriving from in situ and remote observation of the seas and oceans48 the on line access to in situ data
metadata and products is provided through unique portal interconnecting the interoperable node platforms constituted by the seadatanet data centres seadatanet
would like to enhance the cross community expertise on observation networks requirements support and data management expertise by participating in
envriplus more specifically seadatanet would like technology support for cross community ocean solid earth and atmosphere visibility of information provided
by seadatanet platforms metadata datasets vocabulary services as well as expertise on interoperability services and standards generic information about sios
sios svalbard integrated earth observing system is an integral earth observing system built on existing infrastructure in order to better
understand the on going and future climate changes in the arctic49 currently sios is building distributed data management system called
sios knowledge centre to develop methods for how observational networks are to be designed and implemented the centre will lay
the foundation for better coordinated services for the international research community with respect to access to infrastructure data and knowledge
management sharing of data logistics training and education analysis of generic information the following tables summarise the information gathered from
ris and allow for parallel consideration of the replies collected on the generic questions from each ri each table presents
our findings on one of the topics covered by the generic questions the data lifecycle table data and services offered
table data standards and software used table data management table data security and access table non functional constraints table optimisation
plans issues challenges table interactions with other ris and initiatives table table summary of the data lifecycle of the different
ris ri data lifecycle50 actris data from stations are transferred to computational resource acquisition to perform first data quality assurance
qa curation and store it afterwards to one of their topic databases through the actris portal users can visualise and
gain access to data separately publishing combination of doi and code station is used for identification and citation purposes anaee
data is distributed with different facilities belonging to different institutions portal with the ability to identify curation all data held
in anaee is planned data centres are provided at national level publishing european data modelling centre is foreseen for backup
purposes eiscat 3d the eiscat 3d operations centre collects acquisition data from the radar sites production and keeps the full
data set up to pb for three months processing after which all high level data and of the low level
data are archived at two redundant archives the data centres curation data access with authentication will be via an api
and web portal publishing elixir elixir connects bioinformatics activities across its national and international nodes into sustainable european infrastructure for
biological research data elixir research infrastructure provides data publish compute tools processing standards and training for life sciences use core
data resources support all the phases of the data lifecycle acquisition curation publishing processing and use embrc data through sea
sensors or laboratory samples acquisition it does not do any analysis on the data unless it is contracted to do
so it has two main types of data environmental data which is mostly provided free of charge in public databases
publishing embrc acquires the data and submits it in raw form depending on the project to these national or international
open access databases molecular data that is generated by the embrc or by its users the scientists from member institutes
or the users of embrc usually do some work on the data to curate it and if part of bigger
project they may perform some annotation and assembly curation as part of the data policy users who are scientists and
generate molecular data will deposit it in an open access database publishing emso most observatories contribute data to the myocean
copernicus marine environment monitoring service acquisition some data is also contributed to emeco the european marine ecosystem observatory acquisition institutions
gather data and links to the data are made available online to researchers acquisition and curation many observatories store their
own data independently of any dedicated data infrastructure each has its own data management data access services typically via ftp
acquisition emso data may be provided to researchers via different channels publishing each data domain has different policies which any
unified data infrastructure would have to accommodate different data types have different requirements epos each community decides how data is
acquired curated and made available acquisition curation and publishing the data is backed up regularly in federated repositories publishing the
data is made available by the integrated core services interface website or portal publishing metadata will be available in different
formats the data from thematic core services has to be available reasonably quickly pids are used for identification and citation
purposes euro argo observations from argo floats are transmitted to data assembly centre dac acquisition the dac decodes quality controls
and distributes the data curation publishing once month doi is attached to the argo dataset curation on argo gdac the
list of all argo data metadata and technical files is continuously updated publishing eurogoos data from sea sensors with an
acquisition system is transferred to the user ashore acquisition satellite information comes through receiving station production either from the satellite
producers or from an agency forecast data comes from national monitoring programmes acquisition the data are collected acquisition catalogued and
quality assured curation in data centres from different national research institutes they make it available through web portals and discovery
tools publishing and share data and information amongst themselves fixo3 most observatories contribute data to the myocean copernicus marine environment
monitoring service acquisition some data is also contributed to emeco acquisition institutions gather data acquisition and links to the data
curation are made available online to researchers publishing many observatories store their own data independently of any dedicated data infrastructure
each has its own data management and data access services typically via ftp fixo3 has no plans for infrastructure side
data processing iagos raw data is automatically transferred into the reception server acquisition and then validated automatically or manually curation
validated and calibrated data is stored in centralised database from where end users access it via web based data portal
publishing icos three data types are stored raw sensor data collected at the measurement stations acquisition aggregated and quality controlled
observational data produced by expert centres based on the sensor data curation and elaborated data produced by researchers external to
icos but based on icos observational data curation all relevant data will be accessible through the carbon portal cp publishing
the cp will provide one stop shop for all icos data products interact the main information provided are the metadata
regarding research monitoring and other activities at the stations acquisition monitoring data is so far not accessible to the public
in most cases principal investigators own the research data of the information is kept at the station level acquisition is
enes2 data is generated by climate modelling groups data is post processed according to the standards and agreements of the
inter comparison project data is ingested at is enes esgf data nodes acquisition and quality controlled curation data is published
to the is enes esgf data infrastructure publishing publication makes metadata available and searchable and data accessible via is enes
portals as well as via apis publishing important data products are replicated to dedicated long term archival centres additional quality
checks are run as pre requisite for doi assignment and availability for doi based data citation lter data acquisition and
quality control is done by the single sites and usually stored locally deims data discovery portal provides central repository of
metadata on research sites data sets and persons curation furthermore it also provides possibility to upload and share data files
from basic and regular sites publishing seadatanet large and diverse sets of data deriving from in situ and remote observation
of the seas and oceans acquisition the research lab or national ocean data centre nodc provides quality controlled data in
delayed mode and curates the data in homogeneous files curation data are made available to users through central portal publishing
from which requests are re directed to the nodc when data access is restricted requests are controlled by the data
managers sios data is made available from each data management system in each organisation data is accessed through data portal
publishing users can access different observation streams from different organisations each organisation manages its own data in future users will
be able to access integrated data sets and services table summary of the data and services offered by the different
ris ri data and services offered actris data free and open access to all data and data products software quality
assurance qa and data analysis instrumentation tna to different calibration centres and laboratories expertise calibration centres offer training and specific
advice to users training training of operators and users in the field of atmospheric science anaee data data and data
products are open services exploitation of that data and analytical and modelling services facilities to forecast the impact of global
changes and feed into public policy eiscat 3d data access to raw and analysed data is restricted according to the
statutes of eiscat with an embargo time for the associate carrying out an experiment quick look overview data is open
for non commercial purposes software reducing raw data into physical parameters visualisation of low level data training courses on the
use of their radar systems elixir data and services covering all stages of data lifecycle embrc data people may share
data on personal basis software for population analysis of genetic and environmental data instrumentation number of buoys that are connected
to various labs it can also provide detectors and lab equipment expertise in taxonomy and specific model organisms literature libraries
with grey literature at several stations emso services data provision and the physical access necessary to run experiments software for
reformatting data not in the desired formats instrumentation facilities for ocean science academics to make requests for usage time on
observatories technically access to deployed resources is limited to academia rather than industry epos data most of the data is
available for any registered users software for building their own systems and for analysing data instrumentation policies for regulating the
tna literature technical reports public through different project websites euro argo data all data are public software for argo floats
data management expertise it can be solicited to provide advice on various topics eurogoos data facilitates data access between its
member institutes processing it does not own platforms for hpc but all of its member institutes do expertise marine domain
and understanding of end users and customers fixo3 data working towards open access to all datasets instrumentation tna technically access
to deployed resources is limited to academia rather than industry training on the use of marine data infrastructures to acquire
data iagos data data open access for research purpose icos data all data products are free aggregated finalised data sets
via the icos carbon portal other types of data can be obtained via the thematic centres or from the pi
of the observation stations processing planning to set up computing facilities to produce elaborated data products based on observations expertise
various topics literature the portal will host database of all relevant scholarly publications interact metadata metadata about research monitoring and
other station activities expertise best practice of grass root level environmental monitoring and in field research is enes2 services activities
to provide future data near processing functionalities processing computational facilities as part of the esgf nodes and portals or is
enes portals interfacing with the is enes data infrastructure expertise on request about their running environment literature website with ri
information lter metadata metadata on research sites lter sites and ltser platforms are centrally available using the lter europe deims
site and dataset registry platform metadata on research sites don have any restrictions in use this includes information on literature
data some of the data shared by the different lter sites are freely available common data policy and data sharing
agreements will be developed in the upcoming years semantics lter is working on common controlled vocabulary envthes as the basis
for md tagging and data tagging for data discovery and harmonisation software tools can be shared with the scientific community
deims extended by lter europe can be shared freely services lter is working on the implementation and use of data
provision services ogc services like wfs wms wcs and sos metadata shared by using ogc csw service endpoints using iso19115
md model and harvesting lists using eml md model for part of the lter network ogc sos data services tereno
are already available seadatanet data most of them are freely available water column some mostly sea bed observation are restricted
but may be made available software software free nemo mikado odv diva oceanotron processing computing resources to host the datasets
expertise data management marine science and standardisation sios data access to observation streams via the data portal computing resources may
bring computing resource in at later stage table summary of the data standards and software used by the different ris
ri data standards software and hardware used actris data standards netcdf cf compliant format nasa ames software linux servers relational
databases anaee data standards oboe ssn ontology oai metadata standard iso compatible with the inspire directive opensearch and pangaea software
management tools for metadata eiscat 3d data standard hdf5 and storage and catalogue system hardware fpga cluster computers software open
to egi and aarc recommendations considering eudat services the b2 family and dirac for cataloguing dcache or irods for data
backend elixir data standards and software covering all stages of data lifecycle embrc data standard gbif metadata standard medin inspire
directive software darwin core emso data standards netcdf odv and swe being encouraged metadata standards iso and an extended version
of dublin core it wants to be able to interoperate with wds via long term data archives like pangaea security
standards iso epos metadata standards cerif metadata model rdf export oai pmh ckan and opensearch epos is open to eudat
solutions software community software libraries dispel4py and obspy euro argo data standards netcdf cf opendap software linux vm matlab scripts
programs perl scripts and scientific calculator caparmor hardware sgi cluster of calculation nodes with total cores with teraflops capacity eurogoos
hardware hpc cluster software matlab python idl fortran proposed metadata standards iso fixo3 data standards netcdf odv oai swe being
encouraged metadata standards iso an extended version of dublin core iso being considered opensearch and pangaea software open source data
reformatting software iagos data standards ascii nasa ames and netcdf format metadata standard iso and align with inspire software flexpart
postgresql and mongodb databases matlab and open source libraries and tools icos data standards csv ascii netcdf data can be
provided in other formats metadata standards text files spreadsheets software different icos components used several software packages windows and microsoft
products considering open source products interact software java script libraries postgresql with postgis umnmapserver engine apache webserver linux server is
enes2 data standards netcdf cf opendap data access protocol thredds metadata standards iso and federated solr lucene software globus ftp
cmor open source community components security catalogues data access services portal parts etc b2find b2drop are being considered hardware heterogeneous
and locally environments at sites according to site specific constraints lter data standards data are not standardised using enveurope data
reporting sheet for file based data exchange some data provided as time series using sos wide range of solutions for
data storage file based csv netcdf excel metadata standards dataset eml iso19115 inspire profile ri documentation deims sites md model
provenance prov being considered software controlled vocabulary poolparty topbraid data storage b2share in testing phase postgresql oracle mysql microsoft access
ftp repository local data repositories gis spatial databases shapefiles grids data files csv net cdf txt xls proprietary formats and
software metadata us lter deims drupal migrating to drupal geonetwork data services in evaluation and testing geoserver north sos suite
etc seadatanet data standards ascii odv medatlas netcdf and segy metadata standards nemo dataset format management iso19115 and iso19139 series
inspire profile oai pmh ogc csw ogc wms ogc wfs ogc swe opendap software geonetwork for csw and iso191 52north
sos and javascript client for swe oceanotron for wms opendap sos wfs sios table summary of data management for the
different ris ri data management actris covers all the topics except the optimisation anaee preparatory phase data management under development
integrated procedure both for data access and modelling is in place in anaee france eiscat 3d covers all stages of
data lifecycle and is defined in the statutes elixir covers all stages of data lifecycle embrc data policy in place
emso epos uses cerif metadata model for data management and exploitation at community level users are free to use any
standards as long as the data is accessible and discoverable by the ics epos does not have data management plan
yet euro argo procedures applied to argo floats from real time decoding to delayed mode procedures are described in argo
data management document eurogoos cataloguing processing and optimisation mostly fixo3 data access policy defined iagos icos icos doesn have data
management plan but all of the topics are covered in the internal discussions and documentation of the ri interact interact
will establish plan for managing metadata and data in the period is enes2 cordex data management plan cmip6 data management
preparation documents lter common data policy and data management plan is in development as the outcome of the elter h2020
project currently data policies and data management plans are defined by the different participating organisations core lter data management functions
cover currently the discovery of ri elements discovery and access to dataset across the different ri elements is under development
seadatanet covers identification and citation curation cataloguing and provenance sios table summary of data security and access for the different
ris ri data security and access actris open data access without login some communities place restriction with password login actris
has different timing to publish data based on the type of data actris does not have any embargo period anaee
anaee data license attached to the data private companies may access platforms at full cost rate with the possibility of
controlling the dissemination of their data academic users are charged at marginal cost and then have to disseminate the data
according to the anaee dissemination rules with academic embargo periods eiscat 3d access to data is restricted according to the
eiscat statutes blue book there is an embargo time for use exclusively by the experiment pi after which the data
are open to all eiscat members quick look data products are openly accessible for non commercial purposes eiscat 3d does
not have security or privacy issues in general but there is one sensitive issue the incidental detection of satellites in
orbit not all of which are white listed for public tracking elixir open access to all publicly available data and
secure controlled access to sensitive human data embrc open data access policy some timing restrictions depending on the purposes of
the originating research private sector users retain the ipr of their generated data emso general open and free data access
policy but some copernicus data is password protected data tracking retrieval may be implemented epos login and password access with
credentials epos has of the data open only small amount of data is not open which is subject to an
embargo period months or paid data euro argo all argo data are public ifremer operates the euro argo data distribution
they follow the security procedures of ifremer it infrastructure eurogoos free and open data access the use of such free
data by research institutes by exchange and copyright agreements some embargo period for publication periods eurogoos do not have set
procedures for security and access metrics about the end users can be obtained directly from their ip addresses fixo3 general
open and free data access policy but some copernicus data is password protected single sign on process before any data
is accessed for accounting reasons iagos data is open but registration is needed password control it needs to be improved
to use certificate based approach icos single sign on system to control and monitor user identification authorisation and authentication for
data and computational resources that require this other icos components thematic centres are using systems that are local to their
host institutes for these purposes interact four levels through open public access pi editorial level station management level and level
of system management is enes2 single sign on across multiple portals as well as authorisation based on membership of various
projects cordex data are available for both commercial and research purposes some modelling centres restrict their data use to non
commercial research and educational purposes lter free access to metadata on ri elements and datasets data are free if collected
in european funded research projects but local restrictions may be applied seadatanet user directory with self registration provided authentication is
managed via central authentication service some data are free sios table summary of non functional constraints for the different ris
ri non functional constraints actris computational environment costs anaee eiscat 3d administrative constraints from funding agencies elixir rapid exponential data
growth and rapid uptake of biomolecular methods embrc maintenance and operational costs emso epos different non functional constraints depending on
the ics or tcs layer like maintenance capital and operational costs euro argo capital costs maintenance costs operational costs security
computational environment in which your software runs eurogoos fixo3 difficult to normalise data management costs iagos maintenance costs supported by
aeris icos capital costs maintenance costs operational costs security privacy interact will be operated and managed by the interact field
stations themselves and is hence quite robust is enes2 annual operating cost of the infrastructure is estimated to be of
lter long term preservation of data common data policy implementation of data services across the ri maintenance and operation costs
security privacy seadatanet long term preservation of data privacy sios table summary of optimisation plans issues challenges for the different
ris ri optimisation plans issues challenges actris data visualisation data provision interoperability between data centre nodes anaee eiscat 3d workflow
definitions data access with searching and visualisation interoperability with other ris and instruments via virtual observatories elixir data interoperability across
research domains embrc common standards and workflows harmonisation of data between labs backup system maintenance of software and their integration
into single platform emso data interoperability across distributed networks and data search epos improve the interoperable aai system taking already
existing software and make it available and scalable across communities euro argo eurogoos data assimilation fixo3 harmonisation of data formats
and protocols across their distributed networks as well harmonise data curation and access iagos data processing icos data and metadata
storage interact moving into the realm of handling actual data concerning active field stations is enes2 share best practices as
fast as new nodes integrate the ri federation data near processing handling volume and distribution of data replication versioning providing
related information for data products provenance user comments usage detailed scientific descriptions needed for usage lter online data documentation data
harmonisation and access to distributed data services seadatanet data policy to involve data providers in the publication of their own
datasets sios table summary of interactions with other ris and initiatives ri interactions with other ris and initiatives actris iagos
and icos from envriplus aerocom outside eu anaee icos lifewatch and lter eiscat 3d coop dirac egi eudat nordic tier
rda elixir few examples include embrc lifewatch and seadatanet embrc emso fixo3 epos might have interactions with other ris to
access some computational services euro argo eurogoos ris for ocean observing from across europe fixo3 emso iagos interested in collaboration
with actris and icos icos interact eudat clinf is enes2 lter eudat icos lifewatch eu bon geobon anaee envriplus ilter
interact tern austrialia saeon south africa neon us seadatanet eurofleet euroargo esonet fixo3 and jerico sios interact emso icos and
gem table below summarises expectations of the ris as to what they will gain by participating in envriplus table summary
of ri expectations from participating in envriplus ri expectations from envriplus actris planning and managing the activity of sensors developing
understanding of how instruments work in extreme conditions improving the capabilities of small sensors anaee homogenous approach on identification and
citation and on cataloguing across ris interoperability between models and data quality control of data produced by platforms eiscat 3d
selecting open and well documented tools increased interoperability between domains elixir establishing closer collaboration with environmental research infrastructures ris and
improving their access to life science data ultimately better interoperability and discoverability of environmental and life science data by users
across atmospheric marine solid earth and biosphere domains embrc establishing collaborations with the environmental community developing and learning about new
standards and best practices developing new standards within inspire which can be used for other datasets exploring new data workflows
which make use of marine biological and ecological data networking with other ris emso ensuring harmonisation of datasets across their
distributed networks handling heterogeneous data formats improving search is also desirable epos improving the interoperable aaai system taking already existing
software and make it available and scalable across communities euro argo designing and pioneering access to and use of cloud
infrastructure with services close to european research data to deliver data subscription services eurogoos learning about other european ris to
decide on the general objectives and services recommendations about the design of their common data systems and data distribution to
end users fixo3 harmonisation of datasets across distributed networks heterogeneous data formats to enhance cross community collaboration improved search is
also desirable iagos improving data discovery metadata standardisation interoperability citation and doi management icos metadata curation including recipes for cataloguing
and storage data object identification and citation collection and handling of provenance information interact recommendations about how to turn primary
data into data products need to be adopted metadata and data standardisation at all levels homogenisation with other ris is
enes2 better understanding of interdisciplinary use cases and end user requirements as well as advice for data catalogues to compare
their model data with other data lter support on data curation and data object identification especially on the aspect of
dynamic data series and identification of results from data queries data services technical support on optimisation of data flows and
annotation integrating of data repository data integration portal seadatanet enhancing the cross community expertise on observation networks requirements support and
data management expertise technology support for cross community visibility of information provided by seadatanet as well as expertise on interoperability
services and standards sios gathered specific topic information each of the topics into which requirements gathering has been partitioned is
presented below by the relevant topic leader see table they introduce their topic and then analyse the requirements information gathered
that primary information updated after this report was produced can be found in the envri community wiki51 identification and citation
analysis introduction identification of data and associated metadata throughout all stages of processing is really central in any ri this
can be ensured by allocating unique and persistent digital identifiers pids to data objects throughout the data lifecycle the pids
allow making unambiguous references to data during curation cataloguing and support provenance tracking they are also necessary requirement for correct
citation and hence attribution of the data by end users as this is only possible when persistent identifiers exist and
are applied in the attribution environmental research infrastructures are often built on large number of distributed observational or experimental sites
run by hundreds of scientists and technicians financially supported and administrated by large number of institutions if this data is
shared under an open access policy it becomes therefore very important to acknowledge the data sources and their providers there
is also strong need for common data citation tracking systems that allow data providers to identify downstream usage of their
data so as to prove their importance and show the impact to stakeholders and the public identification the survey found
large diversity between ris regarding their practices most are using file based storage for their data rather than database technologies
which suggests that it should be relatively straightforward to assign pids to majority of the ri data objects profound gap
in knowledge about what persistent and unique identifiers are what they can be used for and best practices regarding their
use emerged most identifier systems used are based on handles dois from datacite most common followed by epic pids but
some ris rely on formalized file names while majority see strong need for assigning pids to their finalized data individual
files and or databases few apply this to raw data and even fewer to intermediate data indicating pids are not
used in workflow administration also metadata objects are seldom assigned pids costs for maintaining pids are typically not treated explicitly
assignment of pids to other forms of data such as continuous time series is discussed in sections citation note ris
were asked to characterise their designated user community needs but most responded with ri centric requirements this may be because
there was not sufficient opportunity to directly communicate with users normally their highest priority is to improve their productivity in
this case by having as much of the data identification and citation automated see sections and currently users refer to
data sets in publications using dois if available and otherwise provide information about producer year report number etc either in
the article text or in the references section majority of ris feel it is absolutely necessary to allow unambiguous references
to be made to specified subsets of datasets preferably in the citation while few find the ability to create and
later cite collections of individual datasets is important ensuring that credit for producing and to lesser extent curating scientific data
sets is properly assigned is common theme for all ris not the least because funding agencies and other stakeholders require
such performance indicators but also because individual pis want and need recognition of their work connected to this most ris
have strategies for collecting usage statistics for their data products through bibliometric searches quasi automated or manual from scientific literature
but thus often rely on publishers indexing also data object dois conclusion the use of persistent and unique identifiers for
both data and metadata objects throughout the entire data lifecycle needs to be encouraged by providing training and best use
cases there is strong support for promoting credit to data collectors through standards of data citation supporting adding specific sub
setting information to basic doi based reference demonstrating that this can be done easily and effectively and that data providers
can trust that such citations will be made will be priority as it will lead to adoption and improvement of
citation practices curation analysis curation cataloguing and provenance are closely related and all three topics have metadata element requirements that
overlap considerably with one another hence they are often considered together at present there is available information based on the
questionnaires used by the go betweens for ris curation of datasets briefly the responses range from no curation or plans
to detailed information on metadata formats used none referred to data management plan although it is known to be an
essential component within epos many ris have elements of dmp in place in their statutes but these may not be
formulated as dmp yet only one ri mentioned oais the iso iec standard for curation although it is not much
used and when it is the implementations are very varied since it is really an overview architecture rather than metadata
standard with regard to the metadata standards used or required by the ris several use iso19115 inspire but this does
not really provide much curation information one uses cerif which does provide curation information one uses dublin core which does
not provide curation information curation of software none mentioned metadata covering software and its curation except epos using cerif few
use git to manage software most have no curation of software nor plans for this curation of resources used computers
equipment detectors none mentioned metadata for curation of information on these assets curation of user information none mentioned metadata for
curation of user information although it is known that epos uses cerif for this purpose and will use the metadata
for driving aaai and collaborative working conclusion possibly due to the early stage of some ris or due to interacting
with rireps who were not informed about curation it is often dealt with by small group of specialists the requirements
for curation were not made explicit for example none of the ris who responded has appropriate metadata and processes for
curation it is known that epos has plans in place and there are indications of such planning for some of
the others since curation often underpins validation of the quality of scientific decisions and since environmental sciences observe phenomena that
do not repeat in exactly the same form the profile of curation needs raising this should be attempted by awareness
raising programmes beginning with discussions during envriweek spring if it transpires that there is need then best practice guide should
be developed on curation provenance and cataloguing which should be offered to all ris cataloguing analysis regarding the possible items
to be managed in catalogues the ris have shown interest in observation systems and lab equipment most ris manage equipment
which requires management scheduling maintenance monitoring and some of them are managing or would like to manage this with an
information system some are already using standardised approach ogc swe ssn data processing procedures and systems software very few or
none mentioned an interest to support this in catalogue we observe however that this may be necessary as part of
the provision for provenance and as an aid for those developing or formalising new methods observation events not explicitly mentioned
as requirement most of time again this need may emerge when provenance is considered physical samples mentioned by few especially
in bio diversity field processing activities not explicitly mentioned data products or results widely mentioned as being done by existing
systems ebas earlinet cloudnet ckan madrigal deims widely standardised iso iec 191xx compliance is sometimes required with the inspire directive
support for this in the shared common subsystems would prove beneficial once with wis publications widely mentioned however very few
manage the publications on their own links for provenance between publications and datasets are quite commonly required persons and organisations
not explicitly mentioned however this is reference information which is required for the other described items datasets observation systems etc
and for provenance contact points research objects or features of interest mentioned once as feature of interest airports for iagos
as consequence the following three categories of catalogues are cited in the requirements collection reference catalogues which are not developed
by envriplus or within ris but are pre existing infrastructures containing reference information to be used they can also be
considered as gazetteer thesaurus or directories among them we consider catalogues for people and organisations52 publications research objects features of
interest federated catalogues which are pre existing and partly harmonised in an ri but could be federated by envriplus among
them we consider data products or results results observation systems and lab equipment it would be helpful to promote the
management of metadata to improve provenance physical samples data processing procedures systems and software components metadata management should be promoted
to improve provenance finally activity records observation events processing activities usages logs can be considered they should be provided by
ris and harmonised at the envriplus level to link together the catalogues and fulfil the provenance requirements the tracking of
usage of datasets in scientific papers is widely mentioned by ris these activity records need to be harmonised in envriplus
processing analysis data processing or analytics is an extensive domain including any activity or process that performs series of actions
on dataset to distil information bordawekar it is particularly important in scientific domains especially with the advent of the 4th
paradigm and the availability of big data hey it may be applicable at any phase in the data lifecycle from
qa and event recognition close to data acquisition to transformations and visualisations to suit decision makers as results are presented
data analytics methods draw on multiple disciplines including statistics quantitative analysis data mining and machine learning very often these methods
require compute intensive infrastructures to produce their results in suitable time because of the data to be processed huge in
volume or heterogeneity and or because of the complexity of the algorithm model to be elaborated projected moreover these methods
being devised to analyse dataset and produce other data information than can be considered dataset are strongly characterised by the
typologies of their inputs and outputs in some data intensive cases the data handling access transport io and preparation can
be critical factor in achieving results within acceptable costs in fact when analysing the needs of research infrastructures involved in
envriplus we focused on collecting four major aspects that characterise each ri data processing needs input what are the characteristics
of the dataset to be processed this includes dataset typologies volume velocity variety heterogeneity and access methods analytics what are
the characteristics of the processing tasks to be enacted this includes computing needs quantification implementation aspects including programming languages standards
and re use potential output what are the characteristics of the products resulting from the processing this includes typologies volume
variety variety heterogeneity and availability practices statistics what are the scientific motivations leading to the identification of the specific data
processing envisaged by community this includes aspects related to data collection and hypothesis generation each of these are summarised below
input as largely expected ris needs with respect to dataset to be processed are quite diverse because of the diversity
in the datasets that they deal with dataset and related practices are diverse both across ris and within the same
ri for instance in epos there are many communities each having its specific typologies of data and methodologies ftp and
formats netcdf text for making them available time series and tabular data are two very commonly reported types of dataset
to be processed yet they are quite abstract in what concerns volume dataset vary from few kbs to gbs and
tbs in the large majority of cases dataset are made available as files while few infrastructures have plans to make
or are making their data available through ogc services actris the need to homogenise and promote state of the art
practices for data description discovery and access is of paramount importance to provide ris with data processing environment that makes
it possible to easily analyse dataset across the boundaries of ri domains analytics when moving to the pure processing part
it emerged that ris are at diverse levels of development and that there is large heterogeneity for instance the programming
languages currently in use by the ris range from python matlab and to java and fortran the processing platforms range
from the linux servers in the case of actris to hpc approaches exploited in epos no major issues emerged with
respect to licences software in use or produced tends to be open source and freely available in the majority of
cases there is almost no shared or organised approach to make available the data processing tools systematically both within the
ri and outside the ri one possibility suggested by some ris is to rely on ogc wps for publishing data
processing facilities some care needs to be taken balancing the benefits of common solutions with the need to support wide
range of working practices well we return to this in section the platform should be open and flexible enough to
allow scientists to easily plug in and experiment with their algorithms and methods without bothering with the computing platform service
managers to configure the platform to exploit diverse computing infrastructures third party service providers to programmatically invoke the analytics methods
and to support scientists executing existing analytic tasks eventually customising tuning some parameters without requiring them to install any technology
or software output in essence we can observe that the same variety characterising the input is there for the output
also this case however it is less well understood that there is need to make these data available in systematic
way including information on the entire process leading to the resulting data in the case of embrc it was reported
that the results of processing task are to be made available via paper while for epos it was reported that
the dataset are to be published via shared catalogue describing them by relying on the cerif metadata format in many
cases but by no means all output resulting from data processing task should be published to be compliant with open
science practices data processing platform capable of satisfying the needs of scientists involved in ris should offer an easy to
use approach for having access to the datasets that result from data processing task together as far as possible it
should automatically supply the entire set of metadata characterising the task through the provenance framework this would enable scientists to
properly interpret the results and reduce the effort needed to prepare for curation in cases where aspects of the information
are sensitive could jeopardise privacy or have applications that require period of confidentiality the appropriate protection should be provided statistical
only minority of the ris within envriplus responded to the statistics questions within the processing requirements gathering we know from
the envri project that lifewatch had the support of wide range of statistical investigations not just biodiversity as part of
its mission unsurprisingly given the diversity of the component ris there were variety of different attitudes to the statistical aspects
of data collection and analysis one ri is enes felt that data analysis as opposed to collection was not their
primary mission whereas for others within embrc researchers at the university of st andrews reaching conclusions from data is very
much their primary purpose as environmental data collection is the primary aim of many of the ris it appears that
day to day consideration of potential hypotheses underlying data collection is not undertaken hypothesis generation and testing is for scientific
users of the data and could take many forms however some ris lter and icos stressed that general hypotheses were
considered when the data collection programmes and instruments were being designed especially if the data fed into specific projects hypotheses
could be generated after the fact by users after data collection and indeed this would be norm if data collection
is primary service to the wider scientific community ris can be collecting multiple streams of data often as time series
thus there is the potential to undertake multivariate analysis of the data again unsurprisingly given the diversity of science missions
there was no consistency in approaches data could be continuous and discrete be bounded by its very nature or have
bounds enforced after collection data sets are potentially very voluminous total data sets with billions of sample points might be
generated most analysers will be engaging in formal testing of hypotheses rather than data mining although the latter was not
necessarily ruled out many ris had or are going to implement outlier or anomaly detection on their data again unsurprisingly
given the potential uses for the data variety of statistical methods can be undertaken ris did not feel restricted to
working solely within either frequentist or bayesian framework much of the data collected takes the form of time series the
current mission of envriplus will address the aspects of data collection preparation and integration that should provide context for such
statistical approaches the integration of tools and statistical methods and their mapping onto platforms should be supported in an appropriate
virtual research environment or science gateway this requires collaborative building on experience from the eu project biodiversity virtual laboratory biovel
this would fully integrate statistical analysis tools with the data handling and map the processing tasks automatically to appropriate data
intensive subsystems and computational resources the sustainable path which would also promote international exchanges of environmental data analysis methods would
benefit from collaboration with organisations such as the nsf funded science gateway institute54 this environmental analytical virtual laboratory kit is
good example of candidate common subsystem where the balance of core used by many ri communities with tailoring to support
specialised working practices would need careful investigation providing such an integrated combination of data lifecycle support with easily activated and
steered analysis and visualisation tools will improve researcher productivity by removing many hurdles they have to get over today this
will accelerate discovery and evidence production but it will also boost those who take those results and present them to
decision makers this will interact with the arrangements for federation support see section provenance analysis in order to correctly use
and reuse and interpret data within research infrastructure and cross research infrastructures the data evolutionary history must be known in
detail this is especially crucial in environmental sciences in order to understand changes through history from billions years ago up
to recent and current up to picoseconds history the required combinations span time scales span regional scales span species scales
and wide range of observing and sampling strategies this inevitably requires many data pipelines each based on their own research
and observation practices as biological and environmental systems are intricately intertwined these then need to be brought together hence the
criticality of provenance to validate the quality of the ultimate products this history covers all the steps of the data
lifecycle data acquisition detailed information about scientific question and investigation design observation or measurement methods measurement devices and so forth
is needed data curation exact description of qa measurements flagging and annotation of data metadata to assist with correct future
interpretation and data replication data publication which data were accessed which data are not accessible the selection of data can
strongly influence any further results of data processing which query was carried out and when data processing which method was
used for further processing aggregation of data transformation modelling data use scientific knowledge drawn out of data plus the theories
behind it is important to point out that knowing the evolutionary history of data and at very different time scales
is important for any use and reuse of data use and reuse within institutes reuse some years after the investigation
was made reuse by other persons within institutes use and reuse within research infrastructure and cross research infrastructures inter alia
provenance can help to avoid undetected duplication production or storage of datasets in order to have information on those steps
their description has to be tracked as the so called data provenance and made available to data users the requirements
questionnaire with focus on provenance intended to collect whether provenance was already considered in each ri data lifecycle and if
so which system is in use if this was as yet not implemented the next set of questions is grouped
about the ri possible interest in provenance tracking which type of information should be tracked which standards to rely on
and finally which sort of support is expected from envriplus most ris already consider provenance data as essential and are
interested in using provenance recording system among all of the nine ris who gave feedback about provenance only two already
had data provenance recording system embedded in their data processing workflows epos uses the dispel4py workflow engine in verce which
is based on and is able to export to prov whereas in future it is planned to use the cerif
data model and ontology instead is enes2 instead does not specify which software solution is applied but mentions the use
of community tools to manage what has been collected from where and what is the overall transfer status to generate
provenance log files in workflows some such as seadatanet and euro argo interpret provenance as information gathered via metadata about
the lineage data with tools like geonetwork based on metadata standards like iso19139 but the information gathered is not sufficient
to reproduce the data as the steps of processing are not documented in enough detail other ris such as icos
and lter are already providing some provenance information about observation and measurement methods used within the metadata files but are
aware that real tracking tool still needs to be implemented iagos is using the versioning system git for code but
not for the data itself versioning system can only be seen as part of the provenance information sought on which
information is considered to be important the answers range from versioning of data to the generation of data and modification
of the data as well as on who how and why data is used so there seems to be two
interpretations about what provenance should comprise should it enable the community to follow the data back in time and see
all the steps that happened from raw data collection via quality control and aggregation to useful product or should it
enable the data provider as means of tracking the usage of the data including information about users in order to
understand the relevance of the data and how to improve their services these two roles for metadata may be served
by the same provenance collecting system the provenance data is then interpreted via different tools or services regarding the controlled
vocabularies used for the descriptions of the steps for data provenance some ris already use research specific reference tables and
thesauri like envthes and seadatanet common vocabularies there is big interest among the ris to get clear recommendations from envriplus
about the information range provenance should provide this includes drawing an explicit line between metadata describing the dataset and provenance
information also it should be defined clearly whether usage tracking should be part of provenance it is considered as being
very important to get support on automated tracking solutions and or provenance management apis to be applied in the specific
science environments although there are some thesauri already in use there is demand for getting good overview of the existing
vocabularies and ontologies that are ready to use or that need to be slightly adapted for specific purposes there is
strong relationship between the task of identification of data and the provenance task as there must be direct link between
the data and its lineage that can be followed by the interested user provenance tracking is also an important feature
for optimisation the connections with curation and cataloguing is evident which also becomes clear in the ic_2 provenance implementation case55
which aims amongst others at defining minimum information set that has to be tracked finding conceptual model for provenance which
conforms to the needed information maps existing models to the common model and finds repository to store the provenance information
optimisation analysis introduction environmental science now relies on the acquisition of great quantities of data from range of sources the
data might be consolidated into few very large datasets or dispersed across many smaller datasets it may be ingested in
batch or accumulated over prolonged period although efforts are underway to store data in common data stores to use this
wealth of data fast and effectively it is important that the data is both optimally distributed across research infrastructure data
stores and carefully characterised to permit easy retrieval based on range of parameters it is also important that experiments conducted
on the data can be easily compartmentalised so that individual processing tasks can be parallelised and executed close to the
data itself so as to optimise use of resources and provide swift results for investigators we are concerned here with
the gathering and scrutiny of requirements for optimisation more pragmatically we are concerned with how we might develop generically applicable
methods by which to optimise the research output of environmental science research infrastructures based on the needs and ambitions of
the infrastructures surveyed perhaps more so than the other topics optimisation requirements are driven by the specific requirements of those
other topics particularly processing since the intention is to address specific technical challenges in need of refined solutions although implemented
in way that can be generalised to more than one infrastructure for each part of an infrastructure in need for
improvement we must consider what does it mean for this part to be optimal how is optimality measured do relevant
metrics already exist as standard how is optimality achieved is it simply matter of more resources better machines or is
there need for fundamental rethink of approach what can and cannot be sacrificed for the sake of optimality for example
it may be undesirable to sacrifice ease of use for modest increase in the speed at which experiments can be
executed more specifically we want to focus on certain practical and broadly universal technical concerns what bottlenecks exist in the
functionality of for example storage data management subsystems file systems or databases access and delivery of data data processing and
workflow management what are the current peak volumes for data access storage and delivery for parts of the infrastructure what
is the computational complexity of different data processing workflows what are the specific quality of service of experience requirements for
data handling especially for real time data handling overview and summary of optimisation requirements many optimisation problems whether explicitly identified
as such by ris or implicit in the requirements for other topics can be reduced down to ones of data
placement often in relation to specific services resources or actors is the data needed by researchers available from location such
that they can be easily identified retrieved and analysed in whole or in part is it feasible to perform analysis
on data without substantial additional preparation and if not what is the overhead in time and effort required to prepare
the data for processing this latter question in particular relates to the notion of data staging whereby data is placed
and prepared for processing on some computational service whether that is provided on researcher desktop within an hpc cluster or
on web server which in turn concerns the further question of whether data should be brought to where they can
be best computed or instead computing tasks be brought to where the data currently reside given the large size of
many ri primary datasets bringing computation to data is appealing but the complexity of various analyses also often requires supercomputing
level resources which require the data be staged at computing facility such as are brokered in europe by consortia such
as prace data placement is reliant however on data accessibility which is not simply based on the existence of data
in an accessible location but is also based on the metadata associated with the core data that allows it to
be correctly interpreted it is based on the availability of services that understand that metadata and can so interact and
transport the data with minimum of manual configuration or direction reductionism aside the key performance indicator used by most ris
is researcher productivity can researchers use the ri to efficiently locate the data they need do they have access to
all the support available for processing the data and conducting their experiments can they replicate the cited results of their
peers using the facilities provided this raises yet another question how does the service provided to researchers translate to requirements
on data placement and infrastructure availability this is key to intelligent placement of data the existence of constraints that guide
semi autonomous services by conferring an understanding of the fundamental underlying context in which data placement occurs the programming of
infrastructure in order to support certain task workflows is part of this we can now consider how optimisation of data
movement and processing links with the other topics of the data for science theme based on the information acquired from
ris so far relationship with processing the distribution of computation is major concern for the optimisation of computational infrastructure for
environmental science processing can be initiated at the request of users or can be part of the standard regime for
data preparation and analysis embarked on as part of the data pipeline that runs through most environmental science research infrastructures
given dataset an investigator can retrieve the data within to process on their own compute resources ranging from laptop or
desktop to private compute cluster transfer the data onto dedicated resource such as supercomputer or cluster for which they have
leased time and capacity cloud infrastructure provisioned for the purpose or for smaller tasks simply invoke web service or direct
processing of the data on site generally only possible where the investigator has authority to use the site in question
and generally limited to standard analyses that are part of the afore mentioned data pipeline each of these options confers
possibly zero cost for data movement data preparation and process configuration given constraints on compute capacity network bandwidth and quality
of service the most pertinent question in the sphere of optimisation is simply given the sum of all activities engaged
in by the research community at large where should the data be processed it should be noted that the outputs
of data processing are as much of concern as the inputs especially if the curation of experimental results is considered
within the scope of given research infrastructure and fold back into the domain of data curation relationship with provenance good
provenance is fundamental to optimisation in order to be able to anticipate how data will be used by the community
and what infrastructure elements should be able conscripted to provide access to and processing capability over those data it is
necessary to understand as much about the data as possible thus provenance data is key element of knowledge augmented infrastructure
and provenance recording services are major source of the knowledge that needs to be disseminated throughout the infrastructure in order
to realise this ideal provenance is required to answer who what where when why and how regarding the origins of
data and the role of an optimised ri is to infer the answers for each of those things as they
regard the present and future use of those data ensuring that these questions can be asked and answered becomes more
challenging the greater the heterogeneity of the data being handled by the ri and so potential for runtime optimisation in
particular will depend on the solutions for optimisation provided by the provenance task t8 in envriplus as far as optimisation
serving provenance in and of itself is concerned the management of provenance data streams during data processing is the most
likely area of focus preserving the link between data and their provenance metadata is also important particularly in cases where
those metadata are not packaged with their corresponding datasets relationship with curation streamlining the acquisition of data from data providers
is important to many ris both to maximise the range and timeliness of datasets then made available to researchers and
to increase data security by ensuring that it is properly curated with minimal delay reducing the risk of data corruption
or loss is important in general the principal concerns of curation are ensuring the accessibility and availability of research assets
especially but not exclusively data high availability and long term durability require effective replication procedures across multiple sites it would
be expedient to minimise the cost of synchronising replicas and to anticipate where user demand for retrieval is likely to
be so as to minimise network congestion relationship with cataloguing data catalogues are expected to be the main vector by
which data is identified and requested by users regardless of where that data is ultimately accessed from and taken for
processing and analysis as such the optimisation of both querying and data retrieval is of concern relationship with identification and
citation with regard to identification and citation it is necessary to ensure availability of identification services and it is necessary
to direct users to the best replicas of given dataset that would ensure the most effective use of the underlying
network optimisation methodology optimisation of infrastructure is dependent on insight into the requirements and objectives of the set of research
interactions that the infrastructure exists to support this insight is provided by human experts but in variety of different contexts
concerning the immediate context the investigator engaging in an interaction can directly configure the system based on their experience and
knowledge of the infrastructure concerning the design context the creator of service or process can embed their own understanding in
how the infrastructure operates alternatively experts can encode their expertise as knowledge stored within the system which can then be
accessed and applied by autonomous systems embedded within the infrastructure in the first case it is certainly possible and appropriate
to provide certain degree of configurability with data processing services but with the caveat that casual users should not be
confronted with too much fine detail in the second case engineers and designers should absolutely apply their knowledge of the
system to create effective solutions but should also consider the general applicability of their modifications and the resources needed to
realise optimal performance in specific circumstances it is the third case however that is of most interest in the context
of interoperable architectures for environmental infrastructure solutions the ability to assert domain specific information explicitly in generic architecture and thus
allow the system to reconfigure itself based on current circumstances is potentially very powerful one of the goals of envriplus
is to provide an abstraction layer over number of individual research infrastructures and number of shared services that they interact
with the purpose of this is to identify and benefit from sharing substantial parts of the infrastructure see section for
an explanation of the benefits to achieve this every level of the system needs to be well enough described to
support automated management and optimisation see also section for additional benefits from such descriptions as developing and delivering these infrastructures
has to be collaborative to be sustainable see section that development of sufficient descriptions of appropriate detail and quality remains
challenge that may take political as well as technical effort these aspects of optimisation significantly affect the productivity of those
building and running infrastructures they may also reduce operational costs or accelerate the rate at which results and analyses are
returned this last improvement also addresses the highest priority for most ris and that is improving the productivity and success
of their researchers this of course has to be met by effective automation that reduces their chores and distracting data
wrangling it has to be met by improved usability and easier to understand systems making that progress depends on the
productivity of the development work key step towards this is effective pooling of effort and alliances community support analysis we
define community support as subsystem concerned with managing controlling and tracking users activities within an ri and with supporting all
users to conduct their roles in their communities it includes many miscellaneous aspects of ri operations including for example non
exhaustively authentication authorisation and accounting the use of virtual organisations training and helpdesk activities the questions we asked ri communities
focused on aspects functional requirements non functional requirements privacy licensing and performance and training functional requirements the following is summary
of the main functional requirements expressed by the ris not all apply to all ris data portal data portal was
frequently requested by ris many ris already have their own data portal and some of the others are in the
process of developing one data portals provide single point of access to the system and data products both for humans
and machines via apis the following functionalities are commonly requested access control aai authentication and authorisation infrastructure management is requested
by many ris for example is enes2 currently uses oauth2 openid saml and for aai management discovery of services and
data facilities metadata based discovery mechanisms are commonly used accounting the tracking of user activities which is useful for analysing
the impact of the ri is commonly requested for example embrc records where users are going what facilities they are
using and the number of requests the embrc head office will in the future provide system to analyse resource dois
metrics for the number of yearly publications and impact factor and questionnaires submitted to users asking about their experience with
their services lter plans to track the provenance of the data as well as its usage download or access to
data and data services deims56 for example is planning that statistics about users will be implemented mainly to allow for
better planning of provided services features will be implemented by exploiting eudat services provenance support of b2share to track data
usage google analytics is currently used to track the usage of the deims interface issue tracker actris has recently introduced
an issue tracker to link data users and providers and to follow up on feedback on datasets in response to
individual requests community software epos is in the process of deciding which private software to use and how to integrate
it in the data portal in lter the statistical software and different models vsd dynamic soil model landscapedndc regional scale
process model for simulating biosphere atmosphere hydrosphere exchanges etc are provided wiki wiki is often used to organise community information
and as blackboard for collaborative work for community members to add names and responsibilities to list of tasks to be
done sometimes it is also used to keep track of the progress on task both for strategic and it purposes
faq pages and other material targeting more general audience or outreach materials for educational institutes are special type of wiki
page describing more technical aspects of data handling and data products and also system for collecting user feedback mailing lists
twitter and forums are intended to facilitate communication to and from groups of community members forums and mailing lists can
be interlinked so that any message in the mailing list is redirected to the forum and vice versa files and
image repositories represent shared spaces where members and stakeholders can upload download and exchange files they are also fundamental tool
for storing and categorising images and other outreach material shared calendars keep track and disseminate relevant events for community members
tools to organise meetings events and conferences should handle all the aspects of conference meeting programme user registration deadlines document
