may want to read introduction tutorial tutorial one envri reference model an overview tutorial two main processes of the envri
reference model corresponding viewpoint the envri and envriplus projects frontier environmental research increasingly depends on wide range of data and
advanced capabilities to process and analyse them the original envri project common operations of environmental research infrastructures was collaboration in
the esfri env ironment cluster with support from ict experts to develop common science components and services for their facilities
the results are intended to speed up the construction of these environmental sciences research infrastructures and to allow scientists to
use the data and software from each facility to enable multi disciplinary science the work is continuing as part of
the envriplus project environmental research infrastructures providing shared solutions for science and society the focus is on developing common capabilities
including software and services for environmental and infrastructure communities while the environmental sciences research infrastructures are very diverse they face
common challenges including data capture from distributed sensors metadata standardisation management of high volume data workflow execution and data visualisation
common standards deployable services and tools will be adopted by each infrastructure as it progresses into its construction phase the
envri and envriplus projects deliver common reference model the envri reference model or envri rm created by capturing the functional
and other capabilities of each esfri env infrastructure this model and the development driven by the testbed deployments result in
ready to use systems that can be integrated into the environmental research infrastructures the projects put emphasis on synergy between
advanced developments not only among the infrastructure facilities but also with ict providers and related science initiatives these links will
facilitate system deployment and the training of future researchers and ensure that the inter disciplinary capabilities established here remain sustainable
beyond the lifetime of the project introduction purpose and scope rationale basis approaches conformance related work related concepts related reference
models committee reference models consensus reference models consultation reference models other related standards purpose and scope all research infrastructures for
environmental sciences the so called envris although very diverse have some common characteristics enabling them potentially to achieve greater level
of interoperability through the use of common standards and approaches for various functions the objective of the envri reference model
is to develop common framework and specification for the description and characterisation of computational and storage infrastructures this framework can
support the envris to achieve seamless interoperability between the heterogeneous resources of their different infrastructures the envri reference model serves
the following purposes to provide way for structuring thinking that helps the community to reach common vision to provide common
language that can be used to communicate concepts concisely to help discover existing solutions to common problems to provide framework
into which different functional components of research infrastructures can be placed in order to draw comparisons and identify missing functionality
the present wiki document describes the envri reference model which captures computational characteristics of data and operations that are common
in envri research infrastructures and establishes taxonomy of terms concepts and definitions to be used by the envri community the
reference model provides an abstract logical conceptual model it does not impose specific architecture nor does it impose specific design
decisions or constraints on the design of an infrastructure the initial model versions and focused on the urgent and important
issues prioritised for env research infrastructures including data preservation data discovery and access and data publication it defines minimal set
of functionalities to support these requirements the nitial model does not cover engineering mechanisms or the applicability of existing standards
or technologies version of the model incrementally extends these core functionalities version is simplification of the way the reference model
is presented to make it easier to understand and become familiar with version explicitly aligns the rm with lifecycle oriented
view of research data management rationale environmental issues will dominate the 21st century research infrastructures that provide advanced capabilities for
data sharing processing and analysis enable excellent research and play an ever increasing role in the environmental sciences as well
as in solving societal challenges the envriplus project and its predecessor envri project gathers many of the eu esfri and
other environmental infrastructures icos euro argo eiscat 3d lifewatch epos emso etc to find common solutions to common problems including
use of common software solutions the results including the envri reference model will accelerate the construction of these infrastructures and
improve interoperability among them the experiences gained will also benefit building of other advanced research infrastructures the primary objective of
envri is to agree on reference model for joint operations this will enable greater understanding and cooperation between infrastructures since
fundamentally the model will serve to provide universal reference framework for discussing many common technical challenges facing all of the
esfri env infrastructures by drawing analogies between the reference components of the model and the actual elements of the infrastructures
or their proposed designs as they exist now various gaps and points of overlap can be identified the envri reference
model is based on the design experiences of the state of the art environmental research infrastructures with view of informing
future implementation it tackles multiple challenging issues encountered by existing initiatives such as data streaming and storage management data discovery
and access to distributed data archives linked computational network and storage infrastructure data curation data integration harmonisation and publication data
mining and visualisation and scientific workflow management and execution it uses open distributed processing odp standard framework for distributed system
specification to describe the model to our best knowledge there is no existing reference model for environmental science research infrastructures
this work intends to make first attempt which can serve as basis to inspire future research explorations there is an
urgent need to create such model as we are at the beginning of new era the advances in automation communication
sensing and computation enable experimental scientific processes to generate data and digital objects at unprecedentedly great speeds and volumes many
infrastructures are starting to be built to exploit the growing wealth of scientific data and enable multi disciplinary knowledge sharing
in the case of envri most investigated ris are in their planning construction phase the high cost attached to the
construction of environmental infrastructures require cooperation on the sharing of experiences and technologies solving crucial common science issues and challenges
together only by adopting good reference model can the community secure interoperability between infrastructures enable reuse share resources and experiences
and avoid unnecessary duplication of effort the contribution of this work is threefold the model captures the computational requirements and
the state of the art design experiences of collection of representative research infrastructures for environmental sciences it is the first
reference model of this kind which can be used as basis to inspire future research it provides common language for
communication to unify understanding it serves as community standard to secure interoperability it can be used as base to drive
design and implementation common services can be provided which can be widely applicable to various environmental research infrastructures and beyond
basis the envri reference model is built on top of the open distributed processing odp framework odp is an international
standard for architecting open distributed processing systems it provides an overall conceptual framework for building distributed systems in an incremental
manner the reasons for adopting the odp framework in the envri project come from three aspects it enables large collaborative
design activities it provides framework for specifying and building large or complex system that consists of set of guiding concepts
and terminology this provides way of thinking about architectural issues in terms of fundamental patterns or organising principles and being
an international standard odp offers authority and stability odp adopts the object modelling approach to system specification iso iec includes
the formal definitions of the concepts and terminology adopted from object models which serves as the foundation for expressing the
architecture of odp systems the modelling concepts fall into three categories basic modelling concepts for general object based model specification
concepts to allow designers to describe and reason about odp system specifications structuring concepts including organisation the properties of systems
and objects management that correspond to notions and structures that are generally applicable in the design and description of distributed
systems odp is best known for its use of viewpoints viewpoint on system is an abstraction that yields specification of
the whole system related to particular set of concerns the odp reference model defines five specific viewpoints as follows the
enterprise viewpoint which concerns the organisational situation in which business research activity in the current case is to take place
for better communication with envri community in this document we rename it as science viewpoint the information viewpoint which concerns
modelling of the shared information manipulated within the system of interest the computational viewpoint which concerns the design of the
analytical modelling and simulation processes and applications provided by the system the engineering viewpoint which tackles the problems of diversity
in infrastructure provision it gives the prescriptions for supporting the necessary abstract computational interactions in range of different concrete situations
the technology viewpoint which concerns real world constraints such as restrictions on the facilities and technologies available to implement the
system applied to the existing computing platforms on which the computational processes must execute this version of the envri reference
model covers odp viewpoints the science information and computational viewpoints approaches the approach leading to the creation of the envri
reference model is based on the analysis of the requirements of collection of representative environmental research infrastructures which are reported
in two envri deliverables d3 assessment of the state of the art d3 analysis of common requirements for envri research
infrastructures the odp standard is used as the modelling and specification framework which enables the designers from different organisations to
work independently and collaboratively the development starts from core model and will be incrementally extended based on the community common
requirements and interests the reference model will be evaluated by examining the feasibilities in implementations and the refinement of the
model will be based on community feedback conformance conforming environmental research infrastructure should support the common functionalities described in model
overview and the functional and information model described in the envri reference model the envri reference model does not define
or require any particular method of implementation of these concepts it is assumed that implementers will use this reference model
as guide while developing specific implementation to provide identified services and content conforming environmental research infrastructure may provide additional services
to users beyond those minimally required functions defined in this document any descriptive or prescriptive documents that claim to be
conformant to the envri reference model should use the terms and concepts defined herein in similar way related work related
concepts reference model is an abstract framework for understanding significant relationships among the entities of some environment it consists of
minimal set of unifying concepts axioms and relationships within particular problem domain reference model is not reference architecture reference architecture
is an architectural design pattern indicating an abstract solution that implements the concepts and relationships identified in the reference model
different from reference architecture reference model is independent from specific standards technologies implementations or other concrete details reference model can
drive the development of reference architecture or more than one of them it could be argued that reference model is
at its core an ontology conventional reference models osi rm odp oais are built upon modelling disciplines many recent works
such as the dl org digital library reference model are more ontology like both models and ontologies are technologies for
information representation but have been developed separately in different domains modelling approaches have risen to prominence in the software engineering
domain over the last ten to fifteen years traditionally software engineers have taken very pragmatic approaches to data representation encoding
only the information needed to solve the problem in hand usually in the form of language data structures or database
tables modelling approaches are meant to increase the productivity by maximising compatibility between systems by reuse of standardised models simplifying
the process of design by models of recurring design patterns in the application domain and promoting communication between individuals and
teams working on the system by standardisation of the terminology and the best practices used in the application domain on
the other hand ontologies have been developed by the artificial intelligence community since the 1980s an ontology is structuring framework
for organising information it renders shared vocabulary and taxonomies which models domain with the definition of objects and concepts and
their properties and relations these ideas have been heavily drawn upon in the notion of the semantic web traditional views
tend to distinguish the two technologies the main points of argument include but are not limited to models usually focus
on realisation issues the object oriented modelling approach while ontologies usually focus on capturing abstract domain concepts and their relationship
ontologies are normally used for run time knowledge exploitation for knowledge discovery in knowledge base but models normally do not
ontologies can support reasoning while models cannot or do not finally models are often based on the closed world assumption
while ontologies are based on the open world assumption however these separations between the two technologies are rapidly disappearing in
recent developments study shows that ôall ontologies are modelsõ and ôalmost all models used in modern software engineering qualify as
ontologies as evidenced by the growing number of research workshops dealing with the overlap of the two disciplines seke vorte
mdsw swese ontose womm there has been considerable interests in the integration of software engineering and artificial intelligence technologies in
both research and practical software engineering projects we tend to take this point of view and regard the envri reference
model as both model and an ontology the important consequence is that we can explore further in both directions the
reference model can be expressed using modelling language such as uml uml4odp it can then be built into tool chain
to plugin to an integrated development environment such as eclipse which makes it possible to reuse many existing uml code
and software on the other hand the reference model can also be expressed using an ontology language such as rdf
or owl which can then be used in knowledge base in this document we explore principally from model aspects in
another envri task t3 the ontological aspect of the reference model will be exploited finally reference model is standard created
by iso in osi is probably among the earliest reference models which defines the well known layered network communication as
one of the iso standard types the reference model normally describes the overall requirements for standardisation and the fundamental principles
that apply in implementation it often serves as framework for more specific standards this type of standard has been rapidly
adopted and many reference models exist today which can be grouped into categories based on the type of agreement and
the number of people organisations or countries who were involved in making the agreement committee reference model widely based group
of experts nominated by organizations who have an interest in the content and application of the standard build the standard
consensus reference model the principle that the content of the standard is decided by general agreement of as many as
possible of the committee members rather than by majority voting the envri reference model falls into this group consultation reference
model making draft available for scrutiny and comment to anyone who might be interested in it some examples from each
of the categories are discussed below with emphasis on approaches of building the model and technologies the model captures related
reference models committee reference models in this category we look at those defined by international organisations such as the advancing
open standards for the information society oasis the consultative committee for space data systems ccsds and the open geospatial consortium
ogc the open archival information system oais reference model is an international standard created by ccsds and iso which provides
framework including terminology and concepts for archival concept needed for long term digital information preservation and access the oasis reference
model for service oriented architecture soa rm defines the essence of service oriented architecture emerging with vocabulary and common understanding
of soa it provides normative reference that remains relevant to soa as an abstract model irrespective of the various and
inevitable technology evolutions that will influence soa deployment the ogc reference model orm describes the ogc standards baseline and the
current state of the work of the ogc it provides an overview of the results of extensive development by ogc
member organisations and individuals based on rm odp viewpoints orm captures business requirements and processes geospatial information and services reusable
patterns for deployment and provides guide for implementations the reference model for the orchestra architecture rm oa is another ogc
standard the goal of the integrated project orchestra open architecture and spatial data infrastructure for risk management is the design
and implementation of an open service oriented software architecture to overcome the interoperability problems in the domain of multi risk
management the development approach of rm oa is standard based which is built on the integration of various international standards
also using rm odp standard as the specification framework rm oa describes platform neutral abstract model consisting of the informational
and functional aspects of service networks combining architectural and service specification defined by iso ogc w3c and oasis there are
no reference model standards yet for environmental science research infrastructures consensus reference models in this category we discuss those created
by non formal standard organisations the lifewatch reference model developed by the eu lifewatch consortium is specialisation of the rm
oa standard which provides the guidelines for the specification and implementation of biodiversity research infrastructure inherited from rm oa the
reference model uses the odp standard as the specification framework the digital library reference model developed by dl org consortium
introduces the main notations characterising the whole digital library domain in particular it defines different types of systems digital library
digital library system and digital library management system core concepts characterising the digital library universe organisation content functionality user policy
quality and architecture and categories of actors dl end users including content creators content consumers and digital librarians dl managers
including dl designer and dl system administrators and dl software developers the workflow reference model provides common framework for workflow
management systems identifying their characteristics terminology and components the development of the model is based on the analysis of various
workflow products in the market the workflow reference model firstly introduces top level architecture and various interfaces it has which
may be used to support interoperability between different system components and integration with other major it infrastructure components this maps
to the odp computational viewpoint in the second part it provides an overview of the workflow application program interface comments
on the necessary protocol support for open interworking and discusses the principles of conformance to the specifications this maps to
the odp technology viewpoint the agent system reference model provides technical recommendation for developing agent systems which captures the features
functions and data elements in the set of existing agent frameworks different from conventional methods reverse engineering method has been
used to develop the reference model which starts by identifying or creating an implementation specific design of the abstracted system
secondly identifying software modules and grouping them into the concepts and components and finally capturing the essence of the abstracted
system via concepts and components consultation reference models the data state reference model provides an operator interaction framework for visualisation
systems it breaks the visualisation pipeline from data to view into data stages value analytical abstraction visualisation abstraction and view
and types of transforming operations data transformation visualisation transformation and visual mapping transformation using the data state model the study
analyses existing visualisation techniques including scientific visualisations gis 2d multi dimensional plots trees network web visualisation text information landscapes and
spaces and visualisation spread sheets the analysis results in taxonomy of existing information visualisation techniques which help to improve the
understanding of the design space of visualisation techniques the munich reference model is created for adaptive hypermedia applications which is
set of nodes and links that allows one to navigate through the hypermedia structure and that dynamically òadaptsó personalise various
visible aspects of the system to individual userõs needs the munich reference model uses an object oriented formalisation and graphical
representation it is built on top of the dexter model layered structure and extends the functionality of each layer to
include the user modelling and adaptation aspects the model is visually represented using in uml notation and is formally specified
in object constraint language which is part of the uml while these works use similar approach to the development of
the reference model as the envri rm which is based on the analysis of existing systems and abstracts to obtain
the ôessenceõ of those systems major difference is that these works have not normally met with significant feedback or been
formally approved by an existing community with the consequence that they express less authority as standard other related standards data
distribution service for real time systems dds an object management group omg standard is created to enable scalable real time
dependable high performance interoperable data exchanges between publishers and subscribers dds defines high level conceptual model as well as platform
specific model uml notations are used for specification while dds and the envri share many similar views in design and
modelling dds focuses on only one specific issue to model the communication patterns for real time applications while envri aims
to capture overall picture of requirements for environmental research infrastructures published by the web standards consortium oasis in the content
management interoperability services cmis is an open standard that allows different content management systems to inter operate over the internet
specially cmis defines an abstraction layer for controlling diverse document management systems and repositories using web protocols it defines domain
model plus web services and restful atompub bindings that can be used by applications to work with one or more
content management repositories systems however as many other oasis standards cmis is not conceptual model and is highly technology dependent
model overview the research data lifecycle within environmental research infrastructures data acquisition data curation data publishing data processing data use
lifecycle support inter and intra research infrastructure relationships common functions within common lifecycle the research data lifecycle within environmental research
infrastructures the envri and envriplus project investigated collection of more than representative environmental research infrastructures ris from different areas by
examining these research infrastructures and their characteristics common data lifecycle was identified the data lifecycle is structured in five phases
data use data acquisition data curation data publishing data processing and the fundamental reason of the division of the data
lifecycle is based on the observation that all applications services and software tools are designed and implemented around five major
activities acquiring data storing and preserving data making the data publicly available providing services for further data processing and using
the data to derive different data products this data lifecycle is fairly general and all research infrastructures investigated exhibit behaviour
that aligns with its phases consequently the envri rm is structured in line with the five phases of the data
life cycle this lifecycle begins with the acquisition of data from network of integrated data collecting entities seismographs weather stations
robotic buoys human observers or simulators which is then registered and curated within number of data stores belonging to an
infrastructure or one of its delegate infrastructures this data is then made accessible to parties external to the infrastructure as
well as to services within the infrastructure this results in natural partitioning into data acquisition curation and publishing in addition
ris may provide services for processing data the results of this processing can then produce new data to be stored
within the infrastructure finally the broader research community outside of the ri can design experiments and analyses on the published
data and produce new data which in turn can be passed to the same ri or to other ri for
curation publishing and processing restarting the lifecycle the activities of each research infrastructure can align with this lifecycle however research
infrastructures will tend to optimise and concentrate more on some phases for instance some research infrastructures concentrate mostly on the
acquisition of data while others focus their expertise on curation or publishing envri rm assumes that the research infrastructures can
complement and integrate with each other to support the entire data lifecycle integration is achieved through providing set of capabilities
via interfaces invoked within systems or subsystems which can be used within the infrastructures but also across boundaries in the
envri rm an interface is an abstraction of the behaviour of an object that consists of subset of the interactions
expected of that object together with the constraints imposed on their occurrence the research data lifecycle data acquisition in the
data acquisition phase the research infrastructure collects raw data from registered sources to be stored and made accessible within the
infrastructure the data acquisition phase supports collecting raw data from sensor arrays and other instruments as well as from human
observers and brings those data into the data management part ie ict sub systems of the research infrastructure within the
envri rm the acquisition phase is considered to begin upon point of data entry into the ri systems the acquisition
phase as modeled in the envri rm starts from the design of the experiment acquisition is typically distributed across networks
of observatories and stations the data acquired is generally assumed to be non reproducible being associated with specific possibly continuous
event in time and place as such the assignment of provenance particularly data source and timestamp is essential real time
data streams may be temporarily stored sampled filtered and processed based on applied quality control criteria before being ready for
curation control software is often deployed to manage and schedule the execution and monitoring of data flows data collected during
the acquisition phase ultimately enters the data curation phase for preservation usually within specific time period data curation in the
data curation phase the research infrastructure stores manages and ensures access to all persistent data sets produced within the infrastructure
the data curation phase facilitates quality control and preservation of scientific data the data curation functionalities are typically implemented across
one or more dedicated data centres data handled at this phase include raw data products metadata and processed data where
possible processed data should be reproducible by executing the same process on the same source data sets supported by provenance
data operations such as data quality verification identification annotation cataloguing replication and archival are often provided access to curated data
from outside the infrastructure is brokered through independent data access mechanisms there is usually an emphasis on non functional requirements
for data curation satisfying availability reliability utility throughput responsiveness security and scalability criteria data publishing in the data publishing phase
the research infrastructure enables discovery and retrieval of scientific data to internal and external parties the data publishing phase enables
discovery and retrieval of data housed in data resources managed as part of data curation data publishing often provide mechanisms
for presenting or delivering data products query and search tools allow users or upstream services to discover data based on
metadata or semantic linkages data handled during publishing need not be homogeneous when supporting heterogeneous data different types of data
often pulled from variety of distributed data resources can be converted into uniform representations with uniform semantics resolved by data
discovery service services for harvesting compressing and packaging data and metadata as well as encoding services for secure transfer can
be provided data publishing is controlled using rights management authentication and authorisation policies data processing in the data processing phase
the research infrastructure provides toolbox of services for performing variety of data processing tasks the scope of data processing is
very wide the data processing phase enables the aggregation of data from various sources as well as conduct of experiments
and analyses upon that data during this phase data tends to be manipulated leading to both either derived and or
recombined data to support data processing research infrastructure is likely to offer service operations for statistical analysis and data mining
as well as facilities for carrying out scientific experiments modelling and simulation and visualisation performance requirements for processing scientific data
during this phase tend to be concerned with scalability which can be addressed at the level of engineering and technical
solutions to be considered by making use of cloud computing services the data products generated during processing may themselves be
curated and preserver within the ri data use in the data use phase the research infrastructure supports users of an
infrastructure in gaining access to data and facilitating the preservation of derived data products the data use phase provides functionalities
that manage and track users activities while supporting the users to conduct their research activities which may result in the
creation of new data products data handled and produced at this phase are typically user generated data and communications the
data use phase requires supporting activities such as interactive visualisation standardised authentication authorisation and accounting protocols and the use of
virtual organisations this is the most advanced form of data processing at this phase the research infrastructure implements an interface
with the wider world in which it exists lifecycle support inter and intra research infrastructure relationships each research infrastructure supports
the data lifecycle to different degree according to the scope of particular research infrastructure some core activities align strongly with
some of the phases while other phases are not so comprehensively supported in this case the integration of the research
infrastructures and their external supporting systems and services help in the overall fulfilment of the research data lifecycle for these
cases the major integration points are those at the transition between phases of the data lifecycle these integration points are
important to build the internal subsystems of the research infrastructure as well as to integrate the research infrastructure with other
research infrastructures illustration of the major integration reference points between different phases of the data lifecycle the integration points described
as follows refer to the components supporting phase of the data lifecycle however the components being integrated can be within
the same research infrastructure or in different research infrastructures acquisition curation by which components specialized in data acquisition are integrated
with components which manage data curation curation publishing by which components specialized in data curation are integrated with components which
support data publishing acquisition publishing by which components specialized in data acquisition are integrated components which support data publishing curation
processing by which components specialized in data curation are integrated with components which support data processing acquisition processing by which
components specialized in data acquisition are integrated with components which support data processing processing publishing by which the components specialized
in data processing are integrated with components which support data publishing use all by which entities outside the research infrastructure
may be allowed to provide access or use data at different phases of the data lifecycle no notion of direction
is implied in the definition of these points of reference relations with direction only appear when interfaces are superimposed on
reference points and then they can be unidirectional in either or both directions or bidirectional according to the nature of
the interface depending on the distribution of resources in an implemented infrastructure some of these integration points may not be
present in the infrastructure they take particular importance however when considering scenarios where research infrastructure delegates or outsources functionalities to
other infrastructures for example epos and lifewatch both delegate data acquisition and some data curation activities to national level and
or domain specific infrastructures but provide data processing services over the data held by those infrastructures thus reference points and
become of great importance to the construction of those projects common functions within common lifecycle analysis of requirements of environmental
research infrastructures during the envri and envriplus projects has resulted in the identification of set of common functionalities these functionalities
can be classified according to the five phases of the data lifecycle the requirements encompass range of concerns from the
fundamental data collection and storage data discovery and access and data security to more specific challenges data versioning instrument monitoring
and interactive visualisation in order to better manage the range of requirements and in order to ensure rapid verification of
compliance with the envri rm minimal model has been identified which describes the fundamental functionality necessary to describe an environmental
research infrastructure the minimal model is practical tool to produce partial specification of research infrastructure which nonetheless reflects the final
shape of the complete infrastructure without the need for significant refactoring further refinement of the models using the envri rm
allow producing more refined models of designated priority areas according to the purpose for which the models are created radial
depiction of envri rm requirements with the minimal model highlighted the definitions of the minimal set of functions are given
as follows full list of common functions is provided in appendix data acquisition process control functionality that receives input status
applies set of logic statements or control algorithms and generates set of analogue digital outputs to change the logic states
of devices data collection functionality that obtains digital values from sensor instrument associating consistent timestamps and necessary metadata data transmission
functionality that transfers data over communication channel using specified network protocols data curation data quality checking functionality that detects and
corrects or removes corrupt inconsistent or inaccurate records from datasets data identification functionality that assigns global permanent unique identifiers to
data products data cataloguing functionality that associates data object with one or more metadata objects which contain data descriptions data
product generation functionality that processes data against requirement specifications and standardised formats and descriptions data storage preservation functionality that deposits
over the long term data and metadata or other supplementary data and methods according to specified policies and then to
make them accessible on request data publishing access control functionality that approves or disapproves of access requests based on specified
access policies metadata harvesting functionality that regularly collects metadata in agreed formats from different sources resource registration functionality that creates
an entry in resource registry and inserts resource object or reference to resource object with specified representation and semantics data
publication functionality that provides clean well annotated anonymity preserving datasets in suitable format and by following specified data publication and
sharing policies to make the datasets publically accessible or to those who agree to certain conditions of use and to
individuals who meet certain professional criteria data citation functionality that assigns an accurate consistent and standardised reference to data object
which can be cited in scientific publications and or from other data collections semantic harmonisation functionality that unifies similar data
knowledge models based on the consensus of collaborative domain experts to achieve better data knowledge reuse and semantic interoperability data
discovery and access functionality that retrieves requested data from data resource by using suitable search technology data processing data assimilation
functionality that combines observational data with output from numerical model to produce an optimal estimate of the evolving state of
the system data analysis functionality that inspects cleans and transforms data providing data models which highlight useful information suggest conclusions
and support decision making data mining functionality that supports the discovery of patterns in large datasets data extraction functionality that
retrieves data out of unstructured data sources including web pages emails documents pdfs scanned text mainframe reports and spool files
scientific modelling and simulation functionality that supports the generation of abstract conceptual graphical or mathematical models and to run an
instances of those models scientific workflow enactment functionality provided as specialisation of workflow enactment supporting the composition and execution of
computational or data manipulation steps in scientific application important processing results should be recorded for provenance purposes data processing control
functionality that initiates calculations and manages the outputs to be returned to the client data use authentication functionality that verifies
the credentials of user authorisation functionality that specifies access rights to resources the envri reference model the envri reference model
envri rm defines an archetypical environmental research infrastructure the envri rm is structured according to the open distributed processing odp
standard iso iec and as such is defined from five different perspectives the science information and computational viewpoints take particular
priority these viewpoints allow expression of the complex concerns of the research infrastructures at high level of abstraction when building
research infrastructure these viewpoints are important during the design and conceptualisation phases these viewpoints have been defined previously by the
envri project and enhanced by the envriplus project the engineering and technology viewpoints complement the high level abstractions of the
other three viewpoints by describing elements for physically building research infrastructures when building research infrastructure these viewpoints are more relevant
in the implementation and operational phases these viewpoints are being defined as part of the envriplus project science viewpoint information
viewpoint computational viewpoint engineering viewpoint technology viewpoint science viewpoint the science viewpoint sv of the envri rm captures the requirements
for an environmental research infrastructure the science viewpoint defines communities with their from the perspective of the people who perform
their tasks and community behaviours and roles the diagram below achieve their goals as mediated by the infrastructure modelling in
shows the main elements of the science viewpoint and this viewpoint derives the principles and properties of model their relationships
each ellipse contains concept the objects through the analysis of the structure and functionality of arrows connecting the concepts are
directed and organisations people interacting within and around those indicate the relationship between to concepts the label organisations and rules
governing the interactions of the link indicates the type of relationship from this the diagram indicates that sv behaviours are
two requirements engineering efforts in the envri and performed by sv roles this is represented by two envriplus projects revealed
the existence of common lifecycle relationships isperformedby and performs for the data produced shared and processed by research infrastructures the
five phases of the data lifecycle are data acquisition data curation data publishing data processing and data use correspondingly activities
that support these five phases in order to collaboratively conduct scientific research from data collection to the delivery of scientific
results can also be grouped in the same way such groups are called communities in odp the science viewpoint examines
what those communities are what kind of roles they have and what main behaviours they act out communities community roles
community behaviours science viewpoint objects and their relationships sv communities community is collaboration which consists of set of roles agreeing
their objective to achieve stated business purpose by means of set of behaviours the envri rm distinguishes five groups of
behaviours and roles seen as communities which by design align with the five phases of the data lifecycle the five
communities are and data use the definitions of the data acquisition data curation data publication data service provision communities are
based on their objectives data acquisition community collect raw data and bring streams of measurements into system data curation community
curate the scientific data maintain and archive them and produce various data products with metadata data publishing community assist data
publication discovery and access data processing community provide various services applications and software tools to link and recombine data and
metadata in order to derive knowledge data use community make use of data and service products and transfer knowledge into
understanding sv communities notation the community roles and behaviours are described at the following pages community roles community behaviours sv
community roles role in community is prescribing behaviour that can be performed any number of times concurrently or successively role
can be either active typically associated with human actor or passive typically associated with non human actor software or hardware
components active roles are identified in relation to people associated with research infrastructure those who use the research infrastructure to
do science those who work on resources to build maintain and operate the research infrastructure and those who govern manage
and administer the research infrastructure note an individual may be member of more than one community by undertaking different roles
passive roles are identified with subsystems subsystem components and hardware facilities active roles interact with passive roles to achieve their
objectives roles in the data acquisition community roles in the data curation community roles in the data publishing community roles
in the data processing community roles in the data use community roles in the data acquisition community the main objectives
of the data acquisition community is to bring measurements into the system consider typical data acquisition scenario measurement and monitoring
model is designed by designers based on the requirements of environmental scien tists such design decides what data is to
be collected and what metadata is to be associated with it experimental information and instrument conditions technicians configure and calibrate
sensor or sensor network to satisfy the experiment specifications in the case where human sensors are to be used observers
or measurers input the measures to the system by using mobile devices data collectors interact with data acquisition subsystem to
prepare the data or control the flow of data in order to automatically collect and transmit the data the following
roles are identified in data acquisition community environmental scientist an active role which is person who conducts research or performs
scientific investigations using knowledge of various scientific disciplines they may collect process analyse synthesize study report and or recommend action
based on data derived from measurements or observations of for example air rock soil water nature and other sources sensor
passive role which is converter that measures physical quantity and converts it into signal which can be read by an
observer or by an electronic instrument sensor network passive role which is network consisting of distributed autonomous sensors to monitor
physical or environmental conditions measurement model designer an active role which is person who designs the measurements and monitoring models
based on the requirements of environmental scientists technician an active role which is person who develops and deploys sensor instruments
establishing and testing the sensor network operating maintaining monitoring and repairing the observatory hardware measurer an active role which is
person who determines the ratio of physical quantity such as length time temperature etc to unit of measurement such as
the meter second or degree celsius observer an active role which is person who receives knowledge of the outside world
through his senses or records data using scientific instruments data collector an active role which is person who prepares and
collects data the purpose of data collection is to obtain information to keep on record to make decisions about important
issues or to pass information on to others data acquisition subystem in the science viewpoint the data acquisition subsystem is
passive role of the data acquistion community it is the part of the research infrastructure providing functionalities to automate the
process of data acquisition sv data acquisition community roles sv data acquisition community roles notation the behaviours of the data
acquisition community is described at community behaviours roles in the data curation community the data curation community responds to provide
quality data products and maintain the data resources consider typical data curation scenario when data is being imported into curation
subsystem curator will perform the quality checking of the scientific data unique identifiers will be assigned to the qualified data
which will then be properly catalogued by associating necessary metadata and stored or archived the main human roles interacting with
or maintaining data curation subsystem are data curators who manage the data and stora ge administrators who manage the storage
facilities upon registering digital object in repository its handle and the repository name or ip address is registered with globally
available system of handle servers users may subsequently present handle to handle server to learn the network names or addresses
of repositories in which the corresponding digital object is stored here we use more general term pid instead of handle
thus pid manager instead of handle servers and identify the key roles involved in the data curation process we identified
the following roles in this community data curator an active role which is person who verifies the quality of the
data annotates the data catalogues preserves and maintains the data as resource and prepares various required data products semantic curator
an active role which is person who designs and maintains local and global conceptual models and uses those models to
annotate the data and metadata storage administrator an active role which is person who has the responsibilities to design data
storage tune queries perform backup and recovery operations set up raid mirrored arrays and make sure drive space is available
for the network pid manager passive role system or service that assigns persistent global unique identifiers to data and metadata
products the manager invokes external entity the pid service to obtain the pids the manager maintains local catalogue of pids
that are being used to reference data and metadata if the data or metadata in the ri change location or
are removed the pid manager updates this information locally and informs the pid service pid generator passive role public system
or service which generates and assigns persistent global unique identifiers pids to sets of digital objects the pid generator also
maintains public registry of pids for digital objects storage system passive role which includes memory components devices and media that
retain data and metadata for an interval of time catalogue system passive role catalogue system is special type of storage
system designed to support building logical structures for classifying data and metadata data curation subsystem the data curation subsystem is
passive role of the data curation community it is the part of the research infrastructure which stores manages and ensures
access to all persistent data and metadata produced within the infrastructure sv data curation community roles sv data curation community
roles notation the behaviours of the data curation community are described at community behaviours roles in the data publishing community
the objectives of the data publishing community are to publish data and assist discovery and access we consider the scenarios
described by kahn data publication model an originator user with digital material to be made available for public access makes
the material into digital object digital object is data structure whose principal components are digital material or data plus unique
identifier for this material called handle and perhaps other material to get handle the user requests one from an authorised
handle generator user may then deposit the digital object in one or more repositories from which it may be made
available to others subject to the particular itemõs terms and conditions etc the published data are to be discovered and
accessed by data consumers semantic mediator is used to facilitate the heterogeneous data discovery in summary the following roles are
involved in the data publication community data originator either an active or passive role which provides the digital material to
be made available for public access data repository passive role which is facility for the deposition of published data semantic
mediator passive role which is system or middleware facilitating semantic mapping executing mapping and translation rules discovery and integration of
heterogeneous data data publisher an active role is person in charge of supervising the data publishing processes data publishing subsystem
in the science viewpoint the data access subsystem represents passive role of the data publication community it is the part
of the research infrastructure enabling the discovery and retrieval of scientific data the access to this subsystem could require authorisation
at different levels for different roles data consumer either an active or passive role which is an entity who receives
and uses the data metadata harvester pasive role which is system or service collecting metadata which supports the construction selection
of global conceptual model and the production of mapping rules sv data publishing community roles sv data publishing community roles
notation the behaviours of the data publishing community are described at community behaviours roles in the data processing community the
data processing community provides various application services such as data analysis mining simulation and modelling visualisation and experimental software tools
in order to facilitate the use of the data we consider scenarios of service oriented computing paradigm which is adopted
by the envri implementation model and identify the key roles as below these concepts are along the lines of the
existing standards such as oasis reference model for service oriented architecture data provider either an active or passive role which
is an entity providing the data to be used service passive role in which functionality for processing data is made
available for general use service consumer either an active or passive role which is an entity using the services provided
service provider either an active or passive role which is an entity providing the services to be used service registry
passive role which is an information system for registering services capacity manager an active role which is person who manages
and ensures that the it capacity meets current and future business requirements in cost effective manner data processing subsystem in
the science viewpoint the data processing subsystem represents passive role of the data processing community it is the part of
the research infrastructure providing services for data processing these services could require authorisation at different levels for different roles processing
environment planner an active agent that plans how to optimally manage and execute data processing activity using ri services and
the underlying infrastructure resources handling sub activities such as data staging data analysis mining and result retrieval sv data processing
community roles notation the behaviours of the data processing community are described at community behaviours roles in the data use
community the main role in the data use community is user who is the ultimate consumer of data applications and
services depending on the purposes of use user can be one of the following active roles scientist or researcher an
active role which is person who makes use of the data and application services to conduct scientific research technologist or
engineer an active role which is person who develops and maintains the research infrastructure educator or trainer an active role
which is person who makes use of the data and application services for education and training purposes policy maker or
decision maker an active role which is person who makes decisions based on the data evidence investor or consultant private
sector an active role which is person who makes use of the data and application service for predicting markets so
as to make business decisions on producing related commercial products general public media an active role which is person or
organisation interested in understanding the knowledge delivered by an environmental science research infrastructure or discovering and exploring the knowledge base
enabled by the research infrastructure citizen scientist an active role member of the general public who engages in scientific work
often in collaboration with or under the direction of professional scientists and scientific institutions also known as amateur scientist data
use subsystem in the science viewpoint the data use subsystem represents passive role of the data use community it is
the part of the research infrastructure supporting the access of users to an infrastructure the data use subsystem manages and
tracks user activities and supports users to conduct their roles in different communities sv data use community roles notation the
behaviours of the data use community are described at community behaviours sv community behaviours behaviour of community is composition of
actions performed by roles normally addressing specific science requirements in the envri rm the modelling of community behaviours is based
on analysis of the common operations of research infrastructures which has resulted in list of common functions the community behaviours
model focuses on minimal set of requirements community behaviour can be either single function or composition of several functions from
the function list behaviours of the data acquisition community behaviours of the data curation community behaviours of the data publishing
community behaviours of the data processing community behaviours of the data use community behaviours of the data acquisition community the
key behaviours of the data acquisition community through the interaction of the community roles include design experiment behaviour performed by
environmental scientist that designs the scientific experiment which motivates the data acquisition activities design measurement model behaviour performed by measurement
model designer that designs the measurement or monitoring model based on scientific requirements instrument configuration behaviour performed by technician that
sets up sensor or sensor network instrument calibration behaviour performed by technician that controls and records the process of aligning
or testing senso against dependable standards or specified verification processes data collection behaviour performed by data collector that control and
monitor the collection of the digital values from sensor instrument or human sensor such as measurer or observer associating consistent
timestamps and necessary metadata sv data acquisition community behaviours notation the roles of the data acquisition community are described in
community roles behaviours of the data curation community the main behaviours of the data curation community include data quality checking
behaviour performed by data curator that detects and corrects or removes corrupt inconsistent or inaccurate records from data sets data
preservation behaviour performed by data curator that deposits over long term the data and metadata or other supplementary data and
methods according to specified policies and makes them accessible on request data product generation behaviour performed by data curator that
processes data against requirement specifications and standardised formats and descriptions data replication behaviour performed by storage administrator that creates deletes
and maintains the consistency of copies of data set on multiple storage devices data identification behaviour performed by pid manager
which provides unique pid for data and metadata being curated select or build local conceptual model behaviour performed by semantic
curator which supports the annotation of data and metadata data annotation behaviour performed by semantic curator which supports the linking
of data and metadata with local conceptual model sv data curation community behaviours sv data curation community behaviours notation the
roles of the data curation community which are described at community roles behaviours of the data publishing community the data
publishing community may perform the following behaviours data publication behaviour that provides clean well annotated anonymity preserving datasets in suitable
format and by following specified data publication and sharing policies to make the datasets accessible publicly or to those who
agree to certain conditions of use and to individuals who meet certain professional criteria semantic harmonisation behaviour enabled by semantic
mediator that unifies similar data knowledge models based on the consensus of collaborative domain experts to achieve better data knowledge
reuse and semantic interoperability data discovery and access behaviour enabled by data discovery and access system that retrieves requested data
from data resource by using suitable search technology data citation behaviour performed by pid manager that assigns an accurate consistent
and standardised reference to data object in the same way as researchers routinely provide bibliographic reference to printed resources the
ri publishing the data can define the citation contents such as authors and dates for different citation styles sv data
publicaition community behaviours notation the roles of the data publication community are described at community roles behaviours of the data
processing community the following behaviours of the data processing community are modelled coordinate service behaviour performed by service provider to
coordinate the actions of distributed applications in order to reach consistent agreement on the outcome of distributed transactions compose service
behaviour performed by service provider to combine multiple services which can be achieved by either cho reography or orchestration service
choreography is collaboration between service providers and service consumers serviceorchestration is the behaviour that service provider performs internally to realise
service that it provides customise processing environment behaviour performed by processing environment planner to enable data processing subsystem to prepare
customised infrastructure and service platforms for managing specific data processing applications optimally including the planning provisioning and deployment sub activities
describe service behaviour performed by service provider to provide the information needed in order to use service register service behaviour
performed by service provider to make the service visible to service consumers by registering it in service registry these are
general behaviours of service oriented computing model in the context of environmental science research infrastructures data processing community will focus
on the implementation of domain special services in particular those supporting data assimilation data extraction scientific modelling and simulation scientific
workflow enactment see data analysis data mining terminolog and glossary for the definitions of these functionalities sv data processing community
behaviours notation the roles of the data processing community are described at community roles behaviours of the data use community
the data use community can be divided in two main groups the behaviours performed by active roles human actors and
the behaviours performed by passive roles computer resources the first group encompass the activities performed by human actors using the
ri to interact with the different components of the ri this can extend to all the actors in all the
communities defined in the sv in addition to the ones in the use community for these reason these can also
be called community support behaviours or user support the second group corresponds to the behaviours that enable the authorisation authentication
and accounting of the activities of users also known as aaai behaviours co create behaviour performed by active roles which
entails the design and planning of activities for the collection preservation analysis or publishing of research data in partnership with
different communities collaborate behaviour performed by active roles which entails assisting participating in some of the phases of the collection
preservation analysis or publishing of research data contribute behaviour performed by active roles which entails directly collecting preserving analysing or
publishing research data held by the ri according to predefined protocol user behaviour tracking behaviour enabled by community support system
to track the users if the research infrastructure has identity management authorisation mechanisms accounting mechanisms for example data access sub
system is provided then the community support system either include these or work well with them user profile management behaviour
enabled by community support system to support persistent and mobile profiles where profiles will include preferred interaction settings preferred computational
resource settings and so on user working space management behaviour enabled by community support system to support work spaces that
allow data document and code continuity between connection sessions and accessible from multiple sites or mobile smart devices user working
relationships management behaviour enabled by community support system to support record of working relationships virtual group memberships and friends user
group work supporting behaviour enabled by community support system to support controlled sharing collaborative work and publication of results with
persistent and externally citable pids sv data use community behaviours notation the roles of the data use community are described
at community roles information viewpoint the goal of the information viewpoint iv is to provide common abstract model for the
shared research data handled by the infrastructure the focus lies on the data itself without considering any platform specific or
implementation details it is independent from the computational interfaces and functions that manipulate the data or the nature of technology
used to store it similar to high level ontology the iv aims to provide unique and consistent interpretation of the
shared information objects of particular domain the iv specifies the types of the information objects and the relationships between those
types the main purpose of this viewpoint is to provide an abstract model of the lifecycles of the information objects
handled by the ri it also defines the constraints on information objects and the rules governing those lifecycles the models
of the iv are grouped as follows components collections of information objects and action types necessary to support the minimal
set of required functionalities information objects lifecycle descriptions of how information objects change as the infrastructure operates illustrated using allowed
state changes as the effects of the actions information management constraints models of constraints that actions on information objects should
implement to ensure the integrity and preservation of infor mation objects the information viewpoint defines set of iv objects and
the set iv actions acting on those objects the diagram below shows the main elements of the iv and their
relationships each ellipse contains concept the arrows connecting the concepts are directed and indicate the relationship between concepts the label
of the link indicates the type of relationship from this the diagram indicates that an iv object can be created
by an iv action as indicated by the relationship similarly an iv object can becreatespart of another iv object as
indicated by the rispartofelationship in this same way an action can be part of chain of actions this is indicated
by two relationships and elegatesto precedes components and theirinformation viewpoint relationships in the envri rm research data and metadata are
the main information objects managed by an ri for this reason the iv is closely aligned with the research data
lifecycle model iv components the envri rm information viewpoint defines configuration of information objects the behaviour of those objects the
actions that operate on those objects and set of constraints that should always hold for actions applied on objects the
presentation of iv components are organised as follows iv information objects definition of collection of information objects manipulated by the
system iv information object instances definition of valid instances of information objects states detailed description of information object states and
state transitions resulting from actions iv action types definition of events that cause state changes of information objects iv information
objects the iv of the envri rm defines two main types of information objects data and metadata information objects are
used to model the various types of data and metadata manipulated by the ri the iv information objects can be
grouped as follows data research data processed by the ri characterised as persisted data scientific data unique identifiers for the
data identification backup of data metadata data typically related to the design of observation and measurement models complements data by
providing more precise details design specification of the observation and measurement description of the measurement procedure quality assurance qa annotations
concepts from conceptual model an ontology mapping rules which are used for the model to model transformations provenance records management
metadata the data used to identify the states of data and metadata objects data states metadata states information object definitions
specification of investigation design specification of measurements or observations measurement result concept conceptual model qa notation metadata metadata state metadata
catalogue citation persistent data data state unique identifier uid backup mapping rule data provenance service description institution person project community
role iv information object types iv information object types notation information object definitions specification of investigation design this is the
background data needed to understand the overall goal of the measurement or observation it could be the sampling design of
observation stations the network design the description of the setup parameters interval of measurements and so on it usually contains
important data for the allowed evaluations of research results the question of whether sampling design was done randomly or by
stratification determines which statistical methods can be applied investigations and hence measurement and observation results need not be quantitative they
can also be qualitative results like healthy ill or classifications like assignments to biological taxa it is important for data
processing to know whether they are quantitative or qualitative the specification of investigation design can be seen as part of
metadata or as part of the semantic annotation it is important that this description follows certain standards and it is
desirable that the description is machine readable specification of measurements or observations the description of the measurement observation which specifies
what is measured observed how it is measured observed including processes metods and instruments to be used by whom it
is measured observed including project organisation and experimenter observer profile and what the temporal design is single multiple measurements interval
of measurement etc note this specification can be included as metadata or as semantic annotations of the scientific data to
be collected it is important that such design specification is both explicit and correct so as to be understood or
interpreted by external users or software tools ideally machine readable specification is desired measurement result quantitative qualitative or cataloguing determinations
of magnitude dimension and uncertainty to the outputs of observation instruments sensors sensor networks human observers and observer networks concept
identifier name and definition of the meaning of thing abstract or real thing human readable definition by sentences machine readable
definition by relations to other concepts machine readable sentences it can also be meant for the smallest entity of conceptual
model it can be part of flat list of concepts hierarchical list of concepts hierarchical thesaurus or an ontology conceptual
model collection of concepts their attributes and their relations it can be unstructured or structured glossary thesaurus ontology usually the
description of concept and or relation defines the concept in human readable form conceptual models can also be represented in
machine readable formats for instance rdfs or owl those sentences can be used to construct self description it is common
practice to provide both the human readable description and the machine readable description within the same system in this sense
conceptual model can also be seen as collection of human and machine readable sentences they can be local developed within
project or global accepted and used by wider community such as gemet or oboe conceptual models can be used to
annotate data within network of triple stores qa notation notation of the result of quality assessment this notation can be
nominal value out of classification system up to comprehensive machine readable description of the whole qa process in practice this
can be simple flags like valid invalid up to comprehensive descriptions like data set to invalid by xxxxxx on ddmmyy
because of yyyyyyy qa notation can be seen as special annotation to allow sharing with other users the qa notation
should be unambiguously described so as to be understood by others or interpretable by software tools metadata data about data
in scientific applications is used to describe explain locate or make it easier to retrieve use or manage data resource
there have been numerous attempts to classify the various types of metadata as one example niso national information standards organisation
distinguishes between three types of metadata based on their functionality descriptive metadata which describes resource for purposes such as discovery
and identification structural metadata which indicates how compound objects are put together and administrative metadata which provides information to help
manage resource but this is not restrictive different applications may have different ways to classify their own metadata metadata is
generally encoded in metadata schema which defines set of metadata elements and the rules governing the use of metadata elements
to describe resource the characteristics of metadata schema normally include the number of elements the name of each element and
the meaning of each element the definition or meaning of the elements is the semantics of the schema typically the
descriptions of the location physical attributes type text or image map or model and form print copy electronic file the
value of each metadata element is the content sometimes there are content rules and syntax rules the content rules specify
how content should be formulated representation constraints for content allowable content values and so on and the syntax rules specify
how the elements and their content should be encoded some popular syntax used in scientific applications include some popular syntax
includes html hyper text markup language www w3 org markup xml extensible markup language www w3 org xml rdf resource
description framework www w3 org rdf owl web ontology language www w3 org sw sgml standard generalised markup language www
w3 org markup sgml marc machine readable cataloging www loc gov marc mime multipurpose internet mail extensions www ukoln ac
uk metadata resources mime dime direct internet message encapsulation xml coverpages org draft nielsen dime txt such syntax encoding allows
the metadata to be processed by computer program many standards for representing scientific metadata have been developed within disciplines sub
disciplines or individual project or experiments some widely used scientific metadata standards include dublin core purl oclc org metadata dublin_core
cerif common european research information format www eurocris org iso metadata stds org iso by iso tc www isotc211 org
fgdc the federal geographic data committee www fgdc gov standards inspire inspire jrc ec europa eu iso geographic information metadata
standard metadata model closely related to inspire www iso org ddi data documentation initiative www ddialliance org tei the text
encoding initiative www tei org mets metadata encoding and transmission standard www loc gov standards mets mods metadata object description
schema www loc gov standards mods oais reference model for an open archival information system two aspects of metadata give
rise to the complexity in management metadata are data and data become metadata when they are used to describe other
data the transition happens under particular circumstances for particular purposes and with certain perspectives as no data are always metadata
the set of circumstances purposes or perspectives for which some data are used as metadata is called the ôcontextõ so
metadata are data about data in some ôcontextõ metadata can be layered this happens because data objects may move to
different stages during their life in digital environment requiring their association to different layers of metadata at each stage metadata
can be fused with the data however in many applications such as provenance system or distributed satellite image annotation system
the metadata and data are often created and stored separately as they may be generated by different users in different
computing processes stored at different locations and in different types of storage often there is more than one set of
metadata related to single data resource when the existing metadata becomes insufficient users may design new templates to make another
metadata collection efficient software and tools are required to facilitate the management of the linkage between metadata and data such
linkage relationship between metadata and data are vulnerable to failures in the processes that create and maintain them and to
failures in the systems that store their representations it is important to devise methods that reduce these failures metadata state
raw are established metadata which are not yet registered in general they are not shareable in this status registered are
metadata which are inserted into metadata catalogue published are metadata made available to the public the outside world metadata registered
within public catalogues metadata catalogue collection of metadata usually established to make the metadata available to community metadata catalogue can
be exposed through an access service citation published resolvable token linking to persistent data object via an identifier in information
technology terms citation is reference to published data which may include the information related to the data source the owner
of the data source description of the evaluation process if available timestamp marking the access time to the data sources
thus reflecting certain version the equipment used for collecting the data individual sensor or sensor network it is important that
the citation is resolvable which means that the identifiers point to live data sets and that the meaning of the
items above are made clear persistent data data is the representations of information dealt with by information systems and users
thereof as defined in odp iso iec persistent data denotes data that are persisted stored for the long term data
state data state is the condition of an object that determines the set of all sequences of actions or traces
