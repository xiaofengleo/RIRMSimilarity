special types of metadata which are stored in the ri catalogues and linked to specific dataset for this the annotation
service invokes the catalogue service and the data store controller data curation subsystem data annotation data curation subsystem data annotation
notation cv data publishing aside from the curation of scientific data research infrastructure must provide means to access that data
access can be provided in number of ways including the export of curated datasets and the querying of data catalogues
beyond the actual mechanism of access however are the issues of discovery and interpretation specific datasets may be found via
citation the publication of persistent identifiers associated with data or by browsing data catalogues permitting queries over multiple datasets additionally
functionality to allow identifying the location of specific datasets in data stores should exist it should also be possible to
identify the ontologies taxonomies and other semantic metadata associated with datasets or data requests and provide some form of mapping
between representations as necessary the data publishing objects provide broker objects which mediate between data stores and catalogues and presentation
objects virtual laboratories data brokers act as intermediaries for access to data held within the data store objects supporting data
curation semantic brokers enable semantic interpretation brokers are responsible for verifying the agents making access requests and for validating those
requests prior to sending them on to the relevant data curation service the following examples present two important groups of
functionalities provided by the data publishing subsystem concept mapping and data publishing concept mapping the semantic laboratory facilitates three actives
which support linking data and metadata to one or more global models build global conceptual model setup mapping rule and
perform mapping the semantic broker will facilitate updating the data and internal concept model to preserve the mappings by invoking
the catalogue service and the data store controller data publishing subsystem concept mapping data publishing subsystem concept mapping notation publishing
data and metadata the virtual laboratory facilitates the actives which support publishing data and metadata reviewing the data to be
published publishing data and publishing metadata the data broker will facilitate updating the data and metadata catalogues to stablish that
the data has been reviewed as well as storing the new links that make data and metadata publicly accessible these
actions are performed by invoking the appropriate catalogue services and the data store controller data publishing subsystem publishing data data
publishing subsystem publishing data notation cv data processing the processing of data can be tightly integrated into data handling systems
or can be delegated to separate set of services invoked on demand in general the more complicated processing tasks will
require the use of separated services the provision of dedicated processing services becomes significantly more important when large quantities of
data are being curated within research infrastructure scientific data is an example which is often subject to extensive post processing
and analysis in order to extract new results the data processing objects of an infrastructure encapsulate the dedicated processing services
made available to that infrastructure either within the infrastructure itself or delegated to client infrastructure data processing objects data processing
objects notation cv data processing objects are described as set of process controllers representing the computational functionality of registered execution
resources monitored and managed by coordination service the coordination service delegates all processing tasks sent to particular execution resources coordinates
multi stage workflows and initiates execution data may need to be staged onto individual execution resources and results persisted for
future use data channels can be established with resources via their process controllers the following diagrams shows the staging and
persistence of data data staging the internal staging of data within an infrastructure for processing requires coordination between data processing
components which handle the actual processing workflow and data curation components which hold data within the infrastructure the diagram bellow
displays these two groups of objects which integrate part of the processing subsystem data processing requests generally originate from experiment
laboratories which validate requests by invoking an aaai service the experiment laboratory will send process request to coordination service which
interprets the request and starts processing workflow by invoking the required process controller data will be retrieved from the data
store and passed to the execution platform the coordinationservice will request that data transfer service to prepare data transfer data
will be retrieved from the data store and passed to the execution platform the coordination service will request that data
transferservice to prepare data transfer the data transfer service will then configure and deploy data exporter which will handle the
transfer of data between the storage and execution platforms performing data staging data flow is established between all required data
store controllers and process controllers via the data exporter after the data flow is established processing starts processing can include
host of activities such as summarising mining charting mapping amongst many others the details are left open to allow the
modelling of any processing procedure the expected output of the processing activities is derived data product which in turn will
need to be persisted into the ris data stores data processing subsystem data staging data processing subsystem data staging notation
data persistence the persistence of derived data products produced after processing of data within an infrastructure also requires coordination between
data processing components which handle the actual processing workflow and data curation components which hold data within the infrastructure the
diagram bellow displays these two groups of objects which integrate part of the processing subsystem data processing requests generally originate
from experiment laboratories which validate requests by invoking an aaai service the expe riment laboratory can present results and ask
the user if the results need to be stored alternatively the user may configure the service to automatically store the
resulting data in either case after processing the experiment laboratory will send process request to the coordin ation service which
interprets the request and invokes the process controller which will get the result data ready for transfer the data transfer
service will then configure and deploy data importer which will handle the transfer of data between the execution and storage
platforms data flow is established between process controller and data store controller via the data importer after the data flow
is established the data transfer starts the persistence if data will trigger various curation activities including data storage backup updating
of catalogues requiring identifiers and updating records these activities can occurs automatically or just as signals sent out to warn
human users that an action is expected data processing subsystem data persistence data processing subsystem data persistence notation cv data
use research infrastructure is not an isolated entity research infrastructure aims to interact with the broader scientific community in the
envri rm science gateway also known as virtual research environment is assumed to be the main interaction platform for end
users in essence scientific community portal the science gateway is usually web based and provides number of services both for
human users and for remote procedure invocation these services may range from fundamental data discovery and retrieval to more interactive
user contribution and dataset annotation to more social concerning user profiling reputation mechanisms and workflow sharing the data use components
are part of the presentation and service layers the presentation layer includes different types of human interfaces aimed at providing
access to the internal ri resources and services the service layer encapsulates services provided for outside entities that require programmatic
interaction with the ri in this sense the data use subsystem can be subdivided in two object categories human interaction
objects and service objects human interaction objects data use subsystem human interaction objects data use subsystem human interaction objects notation
in the envri rm more complex interactions between the components facilitating data use and other components are mediated by virtual
la boratories these objects are deployed by science gateways in order to provide persistent context for such interactions between certain
groups of users and particular components within the ri the reference model recognises the following specific sub classes of laboratory
field laboratories so named because they interact with raw data sources in the field are used to interact with the
data acquisition components allowing researchers to deploy calibrate and un deploy instruments as part of the integrated data acquisition network
used by an infrastructure to collect its primary raw data field laboratories have the ability to instantiate new inst rument
controllers from the data acquisition set experimental laboratories are used to interact both with curated data and data processing facilities
allowing researchers to deploy datasets for processing and acquire results from computational experimentation semantic laboratories are used to interact with
the semantic models used by research infrastructure to interpret datasets and characteristic meta data regardless of provenance all laboratories must
interact with an aaai service in order to authorise requests and authenticate users of the laboratory before they can proceed
with any privileged activities pid service provides globally readable persistent identifiers pids to infrastructure entities mainly datasets that may be
cited by the community pids can also be assigned to processes services and data sources this service is assumed to
be provided by an external party and is expected to direct agents attempting to read citations to one of the
infrastructure science gateways service objects constantly increasing portion of the interactions with an ris are expected to be carried out
by external systems interacting with data and other resources in this case the service layer becomes relevant services are meant
to provide access to external systems in this case external systems can include other ris universities government agencies industry applications
or other research groups which need to exploit the ris data resources using client programs and the internet as means
to get to those data resources in this form of integration external systems are expected to implement presentation and broker
objects which communicate with the ri services using public interfaces the following diagram shows an example of the use of
service objects to connect an external system which will supply data to an ri the components of the diagram are
the same of those used internally for data acquisition the difference is that the virtual laboratory data broker and data
exporter objects are all part of an external system these components interact with the aaai and data transfer services the
aaai service will authorise the requested action and provide the required credentials the data transfer service will establish the data
interchange channel between the external data exporter and the internal data importer objects data use subsystem service objects example data
use subsystem service objects example notation cv integration points the cv defines the interfaces that support mutual invocation of cv
objects functionality allowing the composition objects to support complex interactions examination of these interfaces permits set of possible bindings to
be derived for each of these bindings the interaction between the bound objects can be specified in order to define
the objects behaviour when such binding occurs this then serves as basis by which to synthesise the computational behaviour of
the entire ri under different use cases the cv describes these use cases in detail by providing six integration models
these interactions can occur between lifecycle phases provided by single ri but also allow integration of components provided by third
parties the interactions define compound bindings between objects that allow the movement of scientific dataset between different parts of research
infrastructure brokered data export the export of user requested data brokered data import the import of user provided data brokered
data query the querying of curated data by users citation the resolution of data and resources cited in publications instrument
integration the integration of new instruments for data acquisition into the infrastructure raw data collection the acquisition of raw data
from integrated data sources the aggregation of these core interactions form minimal computational model for environmental science research infrastructures that
can be used as starting point for modelling real infrastructures cv brokered data export exporting data out of research infrastructure
entails retrieving data from the data curation subsystem and delivering it to an external resource this process must be brokered
by the data use and data publishing subsystems brokered data export brokered data export notation generally requests for data to
be exported to an external resource originate from virtual laboratory all requests are validated by the aaaiservice via its authorise
action interface the laboratory provides an interface to an external resource this might take the form of uri and preferred
data transfer protocol and submits request to data broker in the data publishing subsystem via its data request interface the
data broker will translate any valid requests into actions in this scenario data transfer request is sent to the data
transfer service within the data curation subsystem the data transfer service will configure and deploy data exporter this exporter will
retrieve data from all necessary data stores opening data flow from data store to external resource the exporter is also
responsible for the repackaging of exported datasets where necessary this includes the integration of any additional metadata or provenance information
stored separately within the infrastructure that needs to be packaged with dataset if it is to be used independently of
the infrastructure as such the exporter can invoke the catalogue service to retrieve additional meta information via its export metadata
interface cv brokered data import importing data from sources other than the acquisition network requires that the import be brokered
by the publishing subsystem before data can be delivered into the data curation subsystem brokered data import notation virtual laboratory
can be used by researchers to upload new data into research infrastructure all requests are validated by the aaaiservice via
its authorise action interface the laboratory provides an interface to an external resource this might take the form of uri
and preferred data transfer protocol and submits request to data broker in the data publishing subsystem via its data request
interface the data broker will translate any valid requests into actions in this scenario data transfer request is sent to
the data transfer service with in the data curation subsystem the data transfer service will configure and deploy data importer
the importer will open data flow from an external resource to one or more suitable data stores within the infrastructure
and update records within those stores as appropriate the importer is responsible for the annotation and registration of imported datasets
this generally entails obtaining global persistent identifier for any new datasets and updating the catalogues used by the research infrastructure
to identify and sort its data inventory as such the importer can invoke the catalogue service to update catalogues and
invoke any community used pid service to acquire identifiers cv brokered data query querying curated data resources requires that the
request be brokered by the data publishing subsystem before any results will be retrieved from the data curation subsystem and
delivered to the client from which the source came brokered data query notation any kind of virtual laboratory is able
to query the data held within research infrastructure subject to access privileges governed by the aaai service invoked via its
authorise action interface data requests are forwarded to data broker within the data publishing subsystem which will interpret the request
and contact any internal services needed to fulfil it in this case the data broker will invoke the catalogueservice via
its query data interface the catalogue service will locate the datasets needed to answer any given query and then proceed
to query resources within infrastructure data stores cv instrument integration data acquisition relies on an integrated network of data sources
referred to generically as instruments that provide raw measurements and observations continuously or on demand this network is not necessarily
static new instruments can be deployed and existing instruments can be taken off line or re calibrated throughout the lifespan
of research infrastructure in the reference model modifications to the acquisition network should be performed via virtual laboratory that permits
authorised agents to oversee acquisition and calibrate instruments based on current community practice or environmental conditions instrument integration instrument integration
notation instruments can be added to and removed from data acquisition network by field laboratory provided by science gateway the
field laboratory must be able to provide an instrument controller for any new instrument added in order to allow the
data acquisition subsystem to interact with the instrument deployment un deployment or re calibration of instruments requires authorisation this can
only be provided valid aaai service via its authorise action interface any changes to the data acquisition network must be
registered with an acquisitionservice via its update registry interface the behaviour of an instrument controller can be configured by the
acquisition service by invoking functions on the controller via its configure controller interface field laboratory also provides the means to
calibrate instruments based on scientific best practice where applicable this is done via the instrument controller calibrate instrument interface cv
citation the citation of datasets involves reference to persistent identifiers assigned to objects within research infrastructure such citations are resolved
by referring back to the infrastructure which can then return report describing the data cited data citation notation user or
external service tries to resolve an identifier found in citation with the global pid service used by the research infrastructure
by dereferencing the given identifier that user or service is directed to science gateway used to interact with the infrastructure
from there the desired provenance information about the citation can be immediately retrieved or virtual laboratory can be deployed for
more complex interactions with the research infrastructure cv raw data collection the collection of raw scientific data requires coordination between
the data acquisition phase which extracts the raw data from instruments and the data curation phase which packages and stores
the data raw data collection notation the delivery of raw data into research infrastructure is driven by collaboration between an
acquisition service and data transfer service this process can be configured using field laboratory subject to an aaai service authorisation
via the aaai service authorise action interface regardless the acquisition service identifies the instruments that act as data sources and
provides information on their output behaviour whilst the data transfer service provides data transporter that can establish multiple persistent data
channels between instruments and data stores the data transporter raw data collector can initiate data transfer by requesting data from
one or more instr ument controllers and preparing one or more data store controllers to receive the data the raw
data collector is considered responsible for packaging any raw data obtained into format suitable for curation this may entail chunking
data streams assigning persistent identifiers and associating metadata to the resulting datasets to assist in this raw data collector may
acquire identifiers from pid service it may also want to register the presence of new data and any immediately apparent
data characteristics in infrastructure data catalogues this is done by invoking an update operation on the catalogue service how to
read the model computational viewpoint the computational viewpoint cv is concerned with the modelling of computational objects and the interactions
between their interfaces according to the odp specification the envri rm uses lightweight subset of the full odp specification to
model the abstract computational requirements of an archetypical environmental science research infrastructure the encapsulation of computational objects and interfaces occurs
at conceptual level rather than the implementation level it is perfectly admissible for the functions of given object to be
distributed across multiple computational resources in an implemented infrastructure should that be supported by its architecture if that distribution does
not interfere with the ability to implement all of that object interfaces and thus behaviours likewise the functionalities of multiple
objects can be gathered within single implemented service should that be desired the first class entity of the cv is
the computational object in diagrams each computational object is represented using rectangle with decoration on the upper right corner the
text within the object indicates the name of the object the decoration on the upper right corner is standard uml
notation for component computational object encapsulates set of functions that need to be collectively implemented by service or resource within
an infrastructure to access these functions computational object also provides number of operational interfaces by which that functionality can be
invoked the object also provides number of operational interfaces by which it can itself invoke functions on other objects each
computational object may also have stream interfaces for ferrying large volumes of data within the infrastructure in summary operational interfaces
are used to pass messages between objects used to coordinate general infrastructure operations such as querying data resource or configuring
service given operation interface must be either server interface providing access to functions that can be invoked by other objects
or client interface providing means by which an object operations can be invoked on other objects in diagrams client and
server interfaces are linked using ball and socket notation clients expose sockets half circles whilst servers expose balls complete circles
stream interfaces are used to deliver datasets from one part of the infrastructure to another producer interface streams data to
one or more bound consumer interfaces as long as there is data to transfer and all required consumers are available
to receive that data whether one all or some of the consumers must be available depends on the circumstances of
the data transfer data channels are typically established by operations invoked via operational interfaces which typically negotiate the terms of
the transfer but can persist independently of them which is useful for long term continuous transfers such as from sensor
networks to data stores in diagrams producer and consumer stream interfaces are linked using double arrow notation the arrow head
points away from producers towards consumers the decoration on the port boxes is not standard uml but is used to
distinguish streaming interfaces as well as having interfaces by which to interact with other objects some computational objects possess the
right to create other computational objects this is done typically to deploy transitory services or to demonstrate how an infrastructure
might extend its functionality some objects extend the functionality of other objects these objects possess all the interfaces of the
parent usually in addition to some of their own and can be created by the same source object if the
capability exists in diagrams the ability to create objects is noted by single filled arrow extending from the creating object
to the object being created with the annotation new object if one object extends another then this can be illustrated
using an unfilled arrow from the sub object to the parent with the annotation is each interface on computational object
supports certain type of interaction between objects which determine the bindings that can be made between interfaces binding is simply
an established connection between two or more interfaces in order to support specific interaction between two or more computational objects
client operational interface can be bound to any server operational interface that provides access to the functions that the client
requires likewise producer stream interface can be bound to any consumer stream interface that can consume the data produced by
the former for simplicity client and server interfaces designed to work together in the model share the same name thus
client interface can bind to any server interface and producer interface can bind to any consumer interface when binding is
explicitlyx shown in diagram the binding itself is identified by that shared name once bound via their corresponding interfaces two
objects can invoke functions on one another to achieve some task such as configuration of an instrument or establishment of
persistent data movement channel primitive bindings can be established between any client server pair or producer consumer pair as appropriate
compound bindings between three or more interfaces can be realised via the creation of binding objects special class of transitory
computational object that can be used to coordinate complex interactions by providing primitive bindings to all required interfaces the use
of binding objects removes the imperative to decompose complex interactions into sets of pairwise bindings between objects this suits the
level of abstraction at which the model is targeted given that the specific distribution of control between interacting objects is
often idiosyncratic to different infrastructure architectures the names of binding objects are typically in diagrams to better distinguish them from
basic computational objects italicised note about implementation in principle all computational objects and their interfaces can be implemented as services
or agents within service oriented architecture this is not required however certain objects may be implemented by working groups or
even individuals within the infrastructure organisation bindings between their interfaces implemented by physical interactions or otherwise human oriented processes such
as sending data via email for example in the model field laboratory has the ability to calibrate instruments represented by
instrument controllers via binding of their common calibrate instrument interfaces potentially the field laboratory could be implemented by virtual research
environment within which authorised users can interact online with instruments deployed in the field modifying how they acquire data in
practice the field laboratory may simply abstractly represent the activities of field agents scientists and technicians who actually travel to
sites where instruments are deployed and manually make adjustments this possibility of this kind of human driven implementation of interactions
between computational objects should be accounted for when considering the computational viewpoint of research infrastructure how to use the model
computational viewpoint the computational viewpoint of the model identifies standard set of components and interfaces from which can be derived
standard set of interactions that research infrastructure design should address the model does not specify how those interactions should be
implemented indeed over the course of the lifetime of research infrastructure implementations may change nevertheless the set of the most
important interactions should remain constant regardless of implementation changes someone trying to apply the computational viewpoint of the model to
their existing or planned research infrastructure should conduct two primary activities mapping agents and services to computational objects and defining
the interactions that should occur when two or more interfaces are bound together for each computational object in the model
there should be at least one component or service or group thereof provided by the infrastructure that can provide the
functions described depending on the architecture of the infrastructure there may be multiple candidate particularly for federated infrastructures every such
candidate could provide an instantiation of the given object if no candidates exist then either the infrastructure does not provide
the service embodied by the computational object and it should be clearly understood that this is indeed the case or
the infrastructure is missing functionality that should be implemented to bring it in compliance with the model for each compatible
pair of interfaces operational or stream there exists an interaction that should occur given binding between those two interfaces the
model does not prescribe these interactions instead simply providing the means to identify them compliant research infrastructure should in principle
have well defined description for every possible binding between interfaces on objects that it provides an implementation for in the
above diagram an operational primitive binding has been established between the configure instrument interfaces of an acquisitionservice object and an
instrument controller object as well as stream primitive binding between the deliver raw data interfaces of the acquisition service and
data store controller see how to read the model to understand the above notation and terms thus assuming model compliant
research infrastructure that provides at least one acquisition service and instrument controller there should be specification of what happens when
configure instrument binding occurs between an acquisition service and instrument controller likewise there should be specification of how raw data
is delivered from an instrument represented by the instrument controller to data store represented by its own controller many primitive
two interface bindings are linked in that the establishment of one binding will necessarily lead to the establishment of other
bindings implying unified interaction description this is particularly true for compound bindings where particular binding object is created to establish
pairwise primitive bindings with multiple computational objects that must all contribute to the given interaction compliant research infrastructure must therefore
identify all such compound bindings and should define how any binding objects created to coordinate interactions are instantiated generally as
either an oversight service or as abstractly as distributed process involving agents services participating in the resulting interaction in the
above diagram there exist multiple primitive bindings to central binding object the raw data collector that nonetheless all relate to
single compound interaction describing how the transfer of data from an instrument to data store is configured and managed it
is very important to properly describe the relationship between the individual bindings and how the compound interaction between the various
computational objects involved is produced if constructions like in the diagram above are to be properly understood in the reference
material for the model number of core reference interactions have been described informally to provide starting point for model implementors
interaction specifications whether for primitive or compound interface bindings can take any form deemed suitable by the developers of the
infrastructure for example uml diagrams such as activity or sequence diagrams may be appropriate as might be formal logic model
or bpel workflow or even natural language if the interaction is simple enough conclusions and future work the envri reference
model is work in progress currently attention is focused on three of the five odp viewpoints enterprise information and computational
the remaining viewpoints of engineering and technology have been deferred to later date much work remains stronger correspondence between the
three primary viewpoints is necessary to ensure that the three sub models are synchronised in concept and execution further refactoring
of individual components and further development of individual elements is to be expected as well further development of the presentation
of the model is also essential in order to both improve clarity to readers not expert in odp and in
order to promote coherent position in the immediate next step the following tasks are planned validation the reference model will
be validated from several aspects usability the users from different ris will be invited to use the reference model to
describe the research infrastructures in the envri the feedback will be collected and analysed to improve the definition of the
reference model interoperability the descriptions of different ris will be compared and check the commonality of the operations and validate
the effectiveness of the reference model in realizing the interoperability between ris the development of the use case in the
work package will also be used as the scenario to test the reference model application the linking model and the
reference model will be tested in the application planning systems to check the data resource and infrastructure interoperability semantic linking
model the reference model will be used as an important input for the development of semantic linking model among the
reference model data and infrastructure the linking model provides an information framework to glue different information models of resources and
data the rm couples the semantic description of architectures and provides semantic interoperability between model descriptions it needs to address
fault tolerance optimization and scheduling of linked resources while making trade off between fuzzy logic and full information the linking
model is part of the development effort of the reference model the model is structured to support the semantic interoperability
between data data objects metadata and annotations which is provided by semantic mediation or mapping or translation between descriptions of
data units parameter methods and others and by semantic mediation of nominal and ordinal values and or taxonomies the linking
model will take different aspects into considerations the application such as workflow aspect captures the main characteristics of the application
supported by the research infrastructure including issues such as main flow patterns quality of services security and policies in user
communities and linking them to the descriptions of the data and infrastructures the computing and data aspect focuses on operations
and different data and meta data standards at different phase of data evolution raw data transfer calibration fusion etc and
model them with linking of the data storing accessing delivery and etc on virtualized infrastructure the infrastructure aspect links the
semantic model of the different layers of components in the physical infrastructure such as network elements and topologies and also
the monitoring information of the runtime status of the infrastructure this part will enable the constraint solving of quality constraints
to reserve and allocating resources for high level applications processes appendix common requirements of environmental research infrastructures the following tables
describe the common requirements environmental research infrastructures the requirements are divided in five sets that correspond to the five stages
of the datalifecycle the requirements highlighted on each table are the minimal model data acquisition functions instrument integration instrument configuration
instrument calibration instrument access configuration logging instrument monitoring parameter visualisation real time parameter data visualisation process control data collection real
time data collection data sampling noise reduction data transmission real time data transmission data transmission monitoring definitions functionality that creates
edits and deletes sensor functionality that sets up sensor or sensor network functionality that controls and records the process of
aligning or testing sensor against dependable standards or specified verification processes functionality that reads and or updates the state of
sensor functionality that collects configuration information or run time messages from sensor or sensor network and outputs into log files
or specified media which can be used by routine troubleshooting and in incident handling functionality that checks the state of
sensor or sensor network which can be done periodically or when triggered by events functionality that outputs the values of
parameters and measured variables display device specialisation of parameter visualisation which is subject to real time constraint functionality that receives
input status applies set of logic statements or control algorithms and generates set of analogue digital outputs to change the
logic states of devices functionality that obtains digital values from sensor instrument associating consistent timestamps and necessary metadata specialisation of
data collection which is subject to real time constraint functionality that selects subset of individuals from within statistical population to
estimate characteristics of the whole population functionality that removes noise from scientific data functionality that transfers data over communication channel
using specified network protocols specialisation of data transmission which handles data streams using specified real time transport protocols functionality that
checks and reports the status of data transferring process against specified performance criteria data curation functions definitions data quality functionality
that detects and corrects or removes corrupt inconsistent or inaccurate records from data sets checking data quality functionality that supports
manual quality checking verification data functionality that assigns global permanent unique identifiers to data products identification data functionality that associates
data object with one or more metadata objects which contain data descriptions cataloguing data product functionality that processes data against
requirement specifications and standardised formats and descriptions generation optional may be null data versioning functionality that assigns new version to
each state change of data allows to add and update some metadata descriptions for each version and allows to select
access or delete version of data workflow functionality that interprets predefined process descriptions and control the instantiation of processes and
enactment sequencing of activities adding work items to the work lists and invoking application tools as necessary data storage functionality
that deposits over long term the data and metadata or other supplementary data and methods preservation according to specified policies
and makes them accessible on request data functionality that creates deletes and maintains the consistency of copies of data set
on multiple storage replication devices replica functionality that exports packet of data from on replica transports it to one or
more other replicas and imports synchronisation and applies the changes in the packet to an existing replica data publishing functions
definitions access functionality that approves or disapproves of access requests based on specified access policies control resources functionality that creates
changes or deletes note that reading any form of text and associates them with annotation computational object data specialisation of
resource annotation which allows to associate an annotation to data object annotation metadata functionality that regularly collects metadata in agreed
formats from different sources harvesting resource functionality that creates an entry in resource registry and inserts resource object or reference
to resource registration object in specified representations and semantics metadata specialisation of resource registration which registers metadata object in metadata
registry registration identifier specialisation of resource registration which registers an identifier object in an identifier registry registration sensor specialisation of
resource registration which registers sensor object to sensor registry registration data functionality that converts data from one format to another
format conversion data functionality that encodes information using reduced bits by identifying and eliminating statistical redundancy compression data functionality that
provides clean well annotated anonymity preserving datasets in suitable format and by publication following specified data publication and sharing policies
to make the datasets publicly accessible or to those who agree to certain conditions of use and to individuals who
meet certain professional criteria data citation functionality that assigns an accurate consistent and standardised reference to data object which can
be cited in scientific publications semantic functionality that unifies similar data knowledge models based on the consensus of collaborative domain
experts harmonisation to achieve better data knowledge reuse and semantic interoperability data functionality that retrieves requested data from data resource
by using suitable search technology discovery and access data functionality that displays visual representations of data visualisation data processing functions
definitions data functionality that combines observational data with outputs from numerical model to produce an optimal assimilation estimate of the
evolving state of the system data analysis functionality that inspects cleans and transforms data providing data models which highlight useful
information suggest conclusions and support decision making data mining functionality that supports the discovery of patterns in large data sets
data functionality that retrieves data out of unstructured data sources including web pages emails documents extraction pdfs scanned text mainframe
reports and spool files scientific functionality that supports the generation of abstract conceptual graphical or mathematical models and to run
modelling and an instances of those models simulation scientific functionality provided as specialisation of workflow enactment supporting the composition and
execution of workflow computational or data manipulation steps in scientific application important processing results should be enactment recorded for provenance
purposes scientific functionality that graphically illustrates scientific data to enable scientists to understand illustrate and gain insight visualisation from their
data optional or may be null service functionality that encapsulates the implemented name policy for service instances in service network
naming data functionality that initiates calculations and manages the outputs to be returned to the client processing ontrol data functionality
that checks the states of running service instance processing monitoring data use functions definitions authentication functionality that verifies credential of
user authorisation functionality that specifies access rights to resources accounting functionality that measures the resources user consumes during access for
the purpose of capacity and trend analysis and cost allocation user registration specialisation of resource registration which registers user to
user registry instant messaging functionality for quick transmission of text based messages from sender to receiver interactive functionality that enables
users to control of some aspects of the visual representations of information visualisation event notification functionality that delivers message triggered
by predefined events appendix terminology and glossary acronyms and abbreviations terminology acronyms and abbreviations ccsds consultative committee for space data
systems cmis content management interoperability services cerif common european research information format dds data distribution service for real time systems
envri envrionmental research infrastructure envri_rm envri reference model esfri european strategy forum on research infrastructures esfri env ri esfri environmental
research infrastructure gis geographic information system iec international electrotechnical commission iso international organisation for standardization oais open archival information system
oasis advancing open standards for the information society odp open distributed processing ogc open geospatial consortium omg object management group
orchestra open architecture and spatial data infrastructure for risk management orm ogc reference model osi open systems interconnection owl web
ontology language soa service oriented architecturesoa rm reference model for service oriented architecture rdf resource description framework rm oa reference
model for the orchestra architecture rm odp reference model of open distributed processinguml unified modelling language w3c world wide web
consortium uml4odp unified modelling language for open distributed processing terminology access control functionality that approves or disapproves of access requests
based on specified access policies acquisition service oversight service for integrated data acquisition active role active role is typically associated
with human actor add metadata add additional information according to predefined schema metadata schema this partially overlaps with data annotations
annotate data annotate data with meaning concepts of predefined local or global conceptual models annotate metadata link metadata with meaning
concepts of predefined local or global conceptual models this can be done by adding pointer to concepts within conceptual model
to the data if concepts are terms in and skos rdf thesaurus published as linked data then this would mean
entering the url of the term describing the meaning of the data annotation service oversight service for adding and updating
records attached to curated datasets assign unique identifier obtain unique identifier and associate it to the data authentication functionality that
verifies credential of user authentication service security service responsible for the authentication of external agents making requests of infrastructure services
authorisation functionality that specifies access rights to resources authorisation service security service responsible for the authorisation of all requests made
of infrastructure services by external agents backup copy of persistent data so it may be used to restore the original
after data loss event behaviour behaviour of community is composition of actions performed by roles normally addressing separate business requirements
build conceptual models establish local or global model of interrelated concepts capacity manager an active role which is person who
manage and ensure that the it capacity meets current and future business requirements in cost effective manner carry out backup
replicate data to an additional data storage so it may be used to restore the original after data loss event
special type of backup is long term preservation catalogue service oversight service for cataloguing curated datasets check quality actions to
verify the quality of data citation citation in the sense of it is pointer from published data to the data
source and or the owner of the data source description of the evaluation process if available timestamp marking the access
time to the data sources thus reflecting certain version community collaboration which consists of set of roles agreeing their objective
to achieve stated business purpose concept name and definition of the meaning of thing abstract or real thing human readable
definition by sentences machine readable definition by relations to other concepts machine readable sentences it can also be meant for
the smallest entity of conceptual model it can be part of flat list of concepts hierarchical list of concepts hierarchical
thesaurus or an ontology conceptual model collection of concepts their attributes and their relations it can be unstructured or structured
glossary thesaurus ontology usually the description of concept and or relation defines the concept in human readable form concepts within
ontologies and their relations can be seen as machine readable sentences those sentences can be used to establish self description
it is however practice today to have both the human readable description and the machine readable description in this sense
conceptual model can also be seen as collection of human and machine readable sentences conceptual models can reside within the
persistence layer of data provider or community or outside conceptual models can be fused with the data within network of
triple stores or kept separately coordination service an oversight service for data processing tasks deployed on infrastructure execution resources data
acquisition community community which collects raw data and bring streams of measures into system data acquisition subsystem subsystem that collects
raw data and brings the measures or data streams into computational system data analysis functionality that inspects cleans transforms data
and provides data models with the goal of highlighting useful information suggesting conclusions and supporting decision making data assimilation functionality
that combines observational data with output from numerical model to produce an optimal estimate of the evolving state of the
system data broker broker for facilitating data access upload requests data cataloguing functionality that associates data object with one or
more metadata objects which contain data descriptions data citation functionality that assigns an accurate consistent and standardised reference to data
object which can be cited in scientific publications data collection functionality that obtains digital values from sensor instrument associating consistent
timestamps and necessary metadata data collector an active role which is person who prepares and collects data the purpose of
data collection is to obtain information to keep on record to make decisions about important issues or to pass information
on to others data consumer either an active or passive role which is an entity who receives and use the
data data curation community community which curates the scientific data maintains and archives them and produces various data products with
metadata data curation subsystem subsystem that facilitates quality control and preservation of scientific data data curator an active role which
is person who verifies the quality of the data preserve and maintain the data as resource and prepares various required
data products data discovery access functionality that retrieves requested data from data resource by using suitable search technology data exporter
binding object for exporting curated datasets data extraction functionality that retrieves data out of unstructured data sources including web pages
emails documents pdfs scanned text mainframe reports and spool files data identification functionality that assigns global unique identifiers to data
contents data importer an oversight service for the import of new data into the data curation subsystem data mining functionality
that supports the discovery of patterns in large data sets data originator either an active or passive role which provide
the digital material to be made available for public access data processing control functionality that initiates the calculation and manages
the outputs to be returned to the client data processing subsystem subsystem that aggregates the data from various resources and
provides computational capabilities and capacities for conducting data analysis and scientific experiments data product generation functionality that processes data against
requirement specifications and standardised formats and descriptions data provenance information that traces the origins of data and records all state
changes of data during their lifecycle and their movements between storages data provider either an active or passive role which
is an entity providing the data to be used data publication functionality that provides clean well annotated anonymity preserving datasets
in suitable format and by following specified data publication and sharing policies to make the datasets publically accessible or to
those who agree to certain conditions of use and to individuals who meet certain professional criteria data publication community community
that assists the data publication discovery and access data publication repository passive role which is facility for the deposition of
published data data publishing subsystem subsystem that enables discovery and retrieval of data housed in data resources data quality checking
functionality that detects and corrects or removes corrupt inconsistent or inaccurate records from data sets data service provision community community
that provides various services applications and software tools to link and recombine data and information in order to derive knowledge
data state term used as defined in iso iec at given instant in time data state is the condition of
an object that determines the set of all sequences of actions or traces in which the object can participate data
storage preservation functionality that deposits over long term the data and metadata or other supplementary data and methods according to
specified policies and makes them accessible on request data store controller data store within the data curation subsystem data transfer
service oversight service for the transfer of data into and out of the data curation subsystem data transmission functionality that
transfers data over communication channel using specified network protocols data transporter generic binding object for data transfer interactions data use
community community who makes use of the data and service products and transfers the knowledge into understanding data use subsystem
subsystem that provides functionalities to manage control and track users activities and supports users to conduct their roles in the
community describe service describe the accessibility of service or process which is available for reuse the interfaces the description of
behaviour and or implemented algorithms design of measurement model behaviour that designs the measurement or monitoring model based on scientific
requirements do data mining execute sequence of metadata data request interpret result do new request education or trainee an active
role person who makes use of the data and application services for education and training purposes environmental scientist an active
role which is person who conduct research or perform investigation for the purpose of identifying abating or eliminating sources of
pollutants or hazards that affect either the environment or the health of the population using knowledge of various scientific disciplines
may collect synthesize study report and recommend action based on data derived from measurements or observations of air food soil
water and other sources envri reference model common ontological framework and standards for the description and characterisation of computational and
storage systems of esfri environmental research infrastructures experiment laboratory community proxy for conducting experiments within research infrastructure field laboratory community
proxy for interacting with data acquisition instruments final review review the data to be published which will not likely be
changed again general public media or citizen scientist an active role person who is interested in understanding the knowledge delivered
by an environmental science research infrastructure or discovering and exploring the knowledge base enabled by the research infrastructure instrument controller
an integrated raw data source knowledge base store of information or data that is available to draw on the underlying
set of facts assumptions and rules which computer system has available to solve problem mapping rule configuration directives used for
model to model transformation measurement model designer an active role which is person who design the measurements and monitoring models
based on the requirements of environmental scientists measurement result quantitative determinations of magnitude dimension and uncertainty to the outputs of
observation instruments sensors including human observers and sensor networks measurer an active role which is person who determines the ratio
of physical quantity such as length time temperature etc to unit of measurement such as the meter second or degree
celsius metadata data about data in scientific applications is used to describe explain locate or make it easier to retrieve
use or manage an information resource metadata catalogue collection of metadata usually established to make the metadata available to community
metadata catalogue has an access service metadata harvesting functionality that regularly collects metadata in agreed formats from different sources metadata
state raw are established metadata which are not yet registered in general they are not shareable in this status registered
are metadata which are inserted into metadata catalogue published are metadata made available to the public the outside world within
some metadata catalogues registered passive role passive role is typically associated with non human actor perform mapping execute transformation rules
for values mapping from one unit to another unit or translation rules for concepts translating the meaning from one conceptual
model to another conceptual model translating code lists persistent data term data used as defined in iso iec data is
the representations of information dealt by information systems and users thereof data which are persistent stored perform measurement or observation
measure parameter or observe an event the performance of measurement or observation produces measurement results pid generator passive role system
which assigns persist global unique identifiers to set of digital object pid registry passive role which is an information system
for registering pids pid service external service for persistent identifier assignment and resolution policy or decision maker an active role
person who makes decisions based on the data evidences private sector industry investor or consultant an active role person who
makes use of the data and application service for predicting market so as to make business decision on producing related
commercial products process control functionality that receives input status applies set of logic statements or control algorithms and generates set
of analogue digital outputs to change the logic states of devices process controller part of the execution platform provided by
the data processing subsystem process data process data for the purposes of converting and generating data products calculations statistical processes
simulation models visualisation alpha numerically graphically geographically data processes should be recorded as provenance provenance the pathway of data generation
from raw data to the actual state of data publish data make data public accessible publish metadata make the registered
metadata available to the public qa notation notation of the result of quality assessment this notation can be nominal value
out of classification system up to comprehensive machine readable description of the whole qa process quality assessment qa assessment of
details of the data generation including the check of the plausibility of the data usually the quality assessment is done
by predefined checks on data and their generation process query data send request to data store to retrieve required data
query metadata send request to metadata resources to retrieve metadata of interests observer an active role which is person who
receives knowledge of the outside world through the senses or records data using scientific instruments raw data collector binding object
for raw data collection reference mode reference mode is an abstract framework for understanding significant relationships among the entities of
some environment register metadata enter the metadata into metadata catalogue resource registration functionality that creates an entry in resource registry
and inserts resource object or reference to resource object in specified representations and semantics role role in community is prescribing
behaviour that can be performed any number of times concurrently or successively science gateway community portal for interacting with an
infrastructure scientific modelling and simulation functionality that supports the generation of abstract conceptual graphical or mathematical models and to run
an instance of the model scientist or researcher an active role person who makes use of the data and application
services to conduct scientific research scientific workflow enactment specialisation of workflow enactment which support of composition and execution series of
computational or data manipulation steps or workflow in scientific application important processes should be recorded for provenance purposes security service
oversight service for authentication and authorisation of user requests to the infrastructure semantic annotation link from thing single datum data
set data container to concept within conceptual model enabling the discovery of the meaning of the thing by human and
machines semantic broker broker for establishing semantic links between concepts and bridging queries between semantic domains semantic harmonisation behaviour enabled
by semantic mediator that unifies similar data knowledge models based on the consensus of collaborative domain experts to achieve better
data knowledge reuse and semantic interoperability semantic laboratory community proxy for interacting with semantic models semantic mediator passive role which
is system or middleware facilitating semantic mapping discovery and integration of heterogeneous data sensor passive role which is converter that
measures physical quantity and converts it into signal which can be read by an observer or by an electronic instrument
sensor network passive role which is network consists of distributed autonomous sensors to monitor physical or environmental conditions service service
or process available for reuse service consumer either an active or passive role which is an entity using the services
provided service description services and processes which are available for reuse be it within an enterprise architecture within research infrastructure
or within an open network like the internet shall be described to help avoid wrong usage usually such descriptions include
the accessibility of the service the description of the interfaces the description of behavior and or implemented algorithms such descriptions
are usually done along service description standards wsdl web service description language within some service description languages semantic descriptions of
the services and or interfaces are possible sawsdl semantic annotations for wsdl service provider either an active or passive role
which is an entity providing the services to be used service registry passive role which is an information system for
registering services setup mapping rules specify the mapping rules of data and or concepts specification of investigation design this is
the background information needed to understand the overall goal of the measurement or observation it could be the sampling design
of observation stations the network design the description of the setup parameters interval of measurements and so on it usually
contains important information for the allowed evaluations of data the question whether sampling design was done randomly or by strategy
determines which statistical methods that can be applied or not specification of measurements or observations the description of the scientific
measurement model which specifies what is measured how it is measured by whom it is measured and what the temporal
design is single multiple measurements interval of measurement etc specify investigation design specify design of investigation including sampling design geographical
position of measurement or observation site the selections of observations and measurement sites can be statistical or stratified by domain
knowledge characteristics of site preconditions of measurements specify measurement or observation specify the details of the method of observations measurements
storage passive role which is memory components devices and media that retain digital computer data used for computing for some
interval of time storage administrator an active role which is person who has the responsibilities to the design of data
storage tune queries perform backup and recovery operations raid mirrored arrays making sure drive space is available for the network
store data archive or preserve data in persistent manner to ensure continuing accessible and usable subsystem subsystem is set of
capabilities that collectively are defined by set of interfaces with corresponding operations that can be invoked by other subsystems subsystems
are disjoint from each other technician an active role which is person who develop and deploy the sensor instruments establishing
and testing the sensor network operating maintaining monitoring and repairing the observatory hardware technologist or engineer an active role person
who develop and maintains the research infrastructure track provenance add information about the actions and the data state changes as
data provenances unique identifier uid with reference to given possibly implicit set of objects unique identifier uid is any identifier
which is guaranteed to be unique among all identifiers used for those objects and for specific purpose user behaviour tracking
behaviour enabled by community support system that to track the users if the research infrastructure has identity management authorisation mechanisms
accounting mechanisms for example data access subsystem is provided then the community support system either include these or work well
with them user group work supporting behaviour enabled by community support system that to support controlled sharing collaborative work and
publication of results with persistent and externally citable pids user profile management behaviour enabled by community support system that to
support persistent and mobile profiles where profiles will include preferred interaction settings preferred computational resource settings and so on user
working space management behaviour enabled by community support system that to support work spaces that allow data document and code
continuity between connection sessions and accessible from multiple sites or mobile smart devices user working relationships management behaviour enabled by
community support system that to support record of working relationships virtual group memberships and friends virtual laboratory community proxy for
interacting with infrastructure subsystems appendix notation the notation used for the diagrams of the envri rm is based on the
uml notation suggested for odp the uml4odp notation the notation sections include set of tables that describe the uml elements
used to produce the diagrams presenting the different viewpoint models science viewpoint models information viewpoint models computational viewpoint models notation
of science viewpoint models communities sv communities are modelled using an object diagram the following table describes the elements used
in that diagram table notation for community diagrams figure description package in uml notation is grouping element package is used
to group elements and to provide namespace for the grouped elements package may contain other packages thus providing for hierarchical
organization of packages classes objects use cases components nodes node instances etc can all be organized as packages enabling manageable
organization of the elements of uml models objects are used to represent communities in the rm the name refers to
the represented entity the stereotype indicates the namespace where the object is grouped sometimes the stereotype can be an image
the image can be used in place of the figure for odp the stereotype for community is group of people
note is used to provide additional information about diagram if the note refers to specific element in the diagram then
it is connected to that object with simple arc in the following example diagram the package represents an environmental research
infrastructure the infrastructure contains five objects which are all communities notes are used to describe the objectives of each of
the communities figure example of community diagram community roles sv roles are represented using class diagram with packages and classes
table notation for role diagrams figure description package in uml notation is grouping element package is used to group elements
and to provide namespace for the grouped elements package may contain other packages thus providing for hierarchical organization of packages
classes objects use cases components nodes node instances etc can all be organized as packages enabling manageable organization of the
elements of uml models classes are used to represent roles in the rm classes can have additional compartments to express
properties called attributes and behaviours called methods omitting the compartments means that the behaviour and attributes are undefined at the
time of building the diagram name tag indicates the name of the class typically classes are named using no spaces
and starting each word that makes up the name camelcase the stereotype indicates the namespace where the class is grouped
sometimes the stereotype can be an image the image can be used in place of the figure for odp the
stereotype for role is mask in the example diagram the package represents the data curation community the community contains eight
role classes the envri rm provides detailed description of each role in text figure example of sv role diagram community
behaviours sv behaviours are represented using an activity diagram with packages and activities table notation for behaviour diagrams figure description
package in uml notation is grouping element package is used to group elements and to provide namespace for the grouped
elements package may contain other packages thus providing for hierarchical organization of packages classes objects use cases components nodes node
instances etc can all be organized as packages enabling manageable organization of the elements of uml models activities are used
to represent behaviours in the rm name tag indicates the name of the behaviour behaviours are named using short phrase
that describes the event or action being represented the small decoration in the activity indicates that the activity is complex
and can be subdivided into smaller tasks stereotype can be used to indicate the namespace where the activity is grouped
sometimes the stereotype can be an image the stereotype image can be used in place of the figure for odp
the stereotype for behaviour is process icon figure example of sv behaviour diagram in the example diagram the package represents
community data acquisition the community implements four basic behaviours the rm also provides detailed description of each behaviour in text
notation of information viewpoint models information objects iv objects are represented using class diagram table notation for information object diagrams
figure description package in uml notation is grouping element package is used to group elements and to provide namespace for
the grouped elements package may contain other packages thus providing for hierarchical organization of packages classes objects use cases components
nodes node instances etc can all be organized as packages enabling manageable organization of the elements of uml models classes
are used to represent information objects in the rm classes can have additional compartments to express properties called attributes and
behaviours called methods leaving the compartments blank means that the behaviour and attributes are undefined at the time of creating
the diagram name tag indicates the name of the class typically classes are named using no spaces in camelcase the
stereotype indicates the namespace where the class is grouped sometimes the stereotype can be an image the image can be
used in place of the figure for odp the stereotype for information object is an i icon with tag on
top generalisation relationship indicates that one of the two related classes the subclass is considered to be specialized form of
the other the super class generalisation is represented with an arc with blank triangle decoration the blank triangle points to
the super class and the undecorated end is connected to the subclass the generalization relationship is also known as the
inheritance or is relationship aggregation relationship indicates an association that represents part whole or part of relationship aggregation is represented
with an arc with blank rhombus decoration the blank rhombus shape indicates the composite and the undecorated end of the
arc is the component figure example of an iv object diagram in the example diagram the package represents the collection
of all information objects described by the envri rm the stereotype for the package is invariant schemata which indicates that
these are the parts of the model that are stable the main objects are persistent data and metadata the rm
also provides detailed description of each object in the text information actions iv actions are represented using an activity diagram
with packages and activities table notation for action type diagrams figure description package in uml notation is grouping element package
is used to group elements and to provide namespace for the grouped elements package may contain other packages thus providing
for hierarchical organization of packages classes objects use cases components nodes node instances etc can all be organized as packages
enabling manageable organization of the elements of uml models activities are used to represent action in the rm name tag
indicates the name of the action actions are named using short phrase that describes the event or action being represented
the small decoration in the box indicates that the action is complex and can be subdivided into smaller tasks stereotype
can be used to indicate the namespace where the activity is grouped sometimes the stereotype can be an image the
stereotype image can be used in place of the figure for odp the stereotype for information action is an arrow
icon with lowercase i figure example of an iv action types diagram in the example diagram the package represents the
information action types described by the envri rm the stereotype for the package is invariant schemata which indicates that these
are the parts of the model that are stable the rm also provides detailed description of each action in text
information object instances iv objects instances are represented using an object diagram the type of diagram is similar to the
class diagram with the difference that the entities represented are objects not classes object instances have specific state and this
can change depending on the moment when the object is observed object instances are useful for representing the dynamic nature
of the systems table notation for information object instances diagrams figure description package in uml notation is grouping element package
is used to group elements and to provide namespace for the grouped elements package may contain other packages thus providing
for hierarchical organization of packages classes objects use cases components nodes node instances etc can all be organized as packages
enabling manageable organization of the elements of uml models classes are used to represent information objects in the rm classes
can have additional compartments to express properties called attributes and behaviours called methods leaving the compartments blank means that the
behaviour and attributes are undefined at the time of creating the diagram name tag indicates the name of the class
classes are named using no spaces and capitalising the first letter of each word that makes up the name camelcase
the stereotype indicates the namespace where the class is grouped sometimes the stereotype can be an image the image can
be used in place of the figure for odp the stereotype for information object is an i icon with tag
on top objects are used to represent object instances in the rm name tag indicates of the entity the set
of attributes with value assigned characterises the state of the object the stereotype indicates the namespace where the object is
grouped sometimes the stereotype can be an image the image can be used in place of the figure for odp
the stereotype for information object instance is an i icon aggregation indicates an association that represents part whole or part
of relationship aggregation is represented with an arc with blank rhombus decoration the end with the blank rhombus indicates the
composite and the other connects to the component figure example of an iv object diagram in the example diagram the
package represents collection of some information object instances the stereotype for the package is dynamic schemata which indicates that these
are the parts of the model that can change depending on when the system is observed the diagram presents four
sample instances of persistent data objects and three examples of metadata objects the diagram also includes the class definitions of
persistent data and metadata objects for reference state diagrams iv object instances can have different states during their lifespan the
basic information objects persistent data and metadata have specific sets of states associated to them the state changes together with
the iv activities can be used to model the behaviour of data as it is managed by the ri for
this we use state machine diagram the main components of state machine diagrams are activity frames states activities and pseudo
states table notation for information object instances diagrams figure description frames are used to indicate the information object instance being
represented the name indicates the information object instance being modelled states are used to represent the state of an information
object resulting from the effects of an iv action the name tag indicates the state reached by the information object
the small decoration in the box can be included to indicate that the state is complex and can be subdivided
into sub states the arcs connecting states represent information actions applied to objects at given state the arrow end indicates
the resulting state the undecorated end indicates the initial state filled circle is pseudo state it can be used to
model start state or an intermediate connecting state circle with smaller filled circle in the middle is pseudo state to
model an end state decision pseudo state is used to model an exclusive fork in the execution of activities it
can also be used to model exclusive joins after forks fork merge pseudo state is used to model forks and
joints in the execution of activities figure example of an iv information object evolution diagram in the example diagram five
information object instances are presented the possible transitions between states are indicated with arcs labelled using the names of iv
actions evolution of information objects the evolution of information objects can also be represented using activity diagrams activity diagrams combine
iv object instances and iv actions can also be combined into table notation for information object evolution with activity diagrams
figure description package in uml notation is grouping element package is used to group elements and to provide namespace for
the grouped elements package may contain other packages thus providing for hierarchical organization of packages classes objects use cases components
nodes node instances etc can all be organized as packages enabling manageable organization of the elements of uml models activities
