the key task is to compare similarity between entities from different semantic models and measure the similarity distances at different
layers the data layer comparing data values and objects the ontology layer comparing the labels and concepts of entities and
the context layer comparing semantic entities with inclusion of application contexts we posit that the five viewpoints of the envri
reference model are applicable for grouping the different modelling contexts of concern to environmental science research infrastructures different metadata standards
have been observed from those ris that are in operation including nasa dif miled and sensorml118 in emso iso iso
geospatial metadata in seadatanet and iso iso geospatial xml in eurogoos and combination of iso inspire119 and netcdf cf120 based
standards in iagos boulanger in addition we have observed the use of dublin core iso iso iso seadatanet cruise summary
reports121 metadata cerif jeffery and csmd122 these standards can be linked via the information viewpoint of the envri reference model
and mapped to functional subsystems of ris there is prior work mapping information viewpoint concepts in the reference model to
concepts found in those standards zhao the typical process for semantic linking involves several iterations of the following steps pre
processing of features by small set of excerpts of the overall ontology definition to describe specific entity definition of the
search space in the ontology for candidate alignment computation of the similarity between two entities from different ontologies aggregation of
the different similarity results of each entity pair depending on the algorithms used and derivation of the final linking between
entities using different interpretation mechanisms including the analysis of human experts the linking component of oil glues concepts both inside
envri rm and between envri rm and external concepts belonging to outside vocabularies the envri rm ontology only contains limited
set of vocabularies derived from common functionality and patterns so linking envri rm with external ri specific concepts will enable
ri specific extensions to the envri rm vocabulary similarly linking envri rm with external vocabularies provides bridge between those vocabularies
and envri rm and indirectly between the vocabularies themselves notably the internal correspondences between different envri rm viewpoints enterprise information
etc can potentially be used to indirectly link external vocabularies of quite different foci data services infrastructure etc distributed applications
and systems can be described using published ontologies permitting services both internal and external to system to potentially interact with
application components without having had to be explicitly designed to do so provided that they can process the ontology used
to describe the component there already exists work on doing this kind of semantic modelling of computing and network infrastructure
however the modelling of applications running on cloud platforms is less well developed in ortiz the author articulates some of
the challenges facing standardisation of cloud technologies and the lack of concrete formal models is major factor even excluding the
cloud however information models for modern computing infrastructure are often lacking in some dimension for example modern infrastructure modelling languages
must be able to model virtualisation and management of virtualised resources as well as physical resources in ghijsen the authors
describe the infrastructure and network description language indl product of the open grid forum ogf network markup language working group
nml wg indl is designed to be extensible linkable to existing information models and technology independent ndl owl baldine provides
semantic web model for networked cloud orchestration modelling network topologies layers utilities and technologies it extends the network description language
upon which indl is based and uses owl meanwhile zhao presented workflow planning system called network aware workflow qos planner
newqosplanner based on indl newqosplanner is able to select network resources in the context of workflow composition and scheduling longer
term horizon the generation of formal descriptions for complex entities is essential for the mechanisation of processes involving those entities
this is not in question what is in question is the extent to which different systems can be integrated within
common models with shared vocabularies and to what extent we must accept the existence of proliferation of alternative models and
thus have to expend effort in bridging between the resulting heterogeneous concept spaces relationships with requirements and use cases the
linking model is strongly tied to the reference model which provides its core vocabulary the linking model should also itself
contribute vocabulary and relations that are useful for the interoperable architecture design task regarding use cases any of the use
cases might benefit from linking of formal descriptions depending on the extent to which the use cases cross between domains
or make use of formal descriptions that need linking to the reference model concepts particular envriplus cases55 where linking between
different existing standards and vocabularies might be useful include identifying trends in the emergence of mosquito born diseases requires interaction
between number of different data centres and compute providers the description of national biodiversity data archive centre requires formal model
for how data from national facility is to be delivered to and integrated with europe wide data providers domain extension
of existing thesauri issues and implications the question that underlies the semantic linking task is how do we make it
easier to map between different vocabularies autonomous mapping processes are highly error prone and extremely sensitive to the quality of
the underlying taxonomies or ontologies manual mapping requires expert oversight but can be supported by tools current work on oil
to and from cerif mapping within the vre4eic project110 should yield useful results here the base contribution of linking model
in the environmental science research infrastructure domain is the ability to map out the space of existing standards models and
vocabularies being used in different datasets architecture designs instrument specifications service profiles etc used by different research communities and the
ability to associate them via the viewpoints of the envri reference model or its successors this in and of itself
would constitute useful contribution since as it stands it requires substantial research to truly understand the full current research landscape
and even experts views are often narrow focused on particular domain or particular geographic region the standards produced within their
home continent further discussion of the semantic linking technologies can be found in section this takes longer term perspective and
considers relations with strategic issues and other technology topics technologies for the reference model alex hardisty and abraham nieva de
la hidalga cardiff university cu introduction context and scope so what is reference model rm good place to start is
with wikipedia article on reference models123 its opening paragraph explains an rm as an abstract framework consisting of an interlinked
set of clearly defined concepts produced by an expert or body of experts in order to encourage clear communication reference
model can represent the component parts of any consistent idea from business functions to system components it goes on to
say that an rm can then be used to communicate ideas clearly among members of the same community this then
is the essence of an rm it descriptive conceptual framework establishing common language of communication and understanding about elements of
system and their significant relationships within community of interest that particularly important when as in the environmental research infrastructures ri
sector that community of interest brings together significant numbers of experts from vastly different scientific and technical backgrounds to talk
about building distributed ict infrastructures the present topic is concerned principally with the envri reference model124 and is closely related
to the topic of the linking model see which depends upon it however reference models are cutting across all aspects
of infrastructure design and technology review thus this topic relates to all the topics of the technology review see section
sources of state of the art technology information used wikipedia provides general introductory level information on reference models and reference
architectures iso iec publishes relevant international standards various web resources have been used and are mentioned linked in the text
other sources are directly referenced from the text and listed in the bibliography short term analysis of state of the
art and trends state of the art the envri reference model envri rm is presently work in progress based on
rm odp iso iec version has been published in summer as deliverable of the envri project it is derived from
commonalities of requirements collected from research infrastructures in the envriplus project there is task to review and improve the rm
based on new requirements analysis of research infrastructures125 at present the envri rm is introduced through sub systems view of
research infrastructure but this needs to shift to data lifecycle oriented approach the sub systems perspective has to be more
properly assigned only within the engineering viewpoint where it can support the complete lifecycle of research data from design of
experiments that produce new data through acquisition curation and publishing of that data to its use in processing and analysis
to reach scientific conclusions according to specific scope and needs of individual ris moving forward with the rm in envriplus
use of reference models and particularly viewpoint models such as envri rm keeps the design discussion centred at the right
level see remarks on raising the level of discourse while accommodating the perspectives of difference stakeholders they allow moving from
high level description of ris for researchers and sponsors that is founded on the science to be carried out to
lower more detailed design level for it developers and technicians concerning engineering and technology aspects by using the envri rm
ris can create set of models that separate concerns neatly but at the same time keep the consistency of the
ri systems as complete entity as well as accommodating relevant policy constraints validating the present envri rm based on review
of requirements from wider set of ris and completing and evolving the rm for easier use are main activities in
the envriplus project now another important activity is to explore ways in which ris communities can be helped and assisted
to become self sufficient working in conjunction with several use cases teams see below and producing specialised learning materials are
two strands of planned activity as well as delivering content specifically about the internals of the envri rm training will
also give guidance for different situations on how to use various parts of the rm this will be very much
driven by case examples and over time we expect to see emergence of common re usable patterns that can be
applied elsewhere it would be interesting to find an early adopter ri prepared to invest in exploring the potential of
the available tools see above casting model in uml4odp perhaps problems to be overcome adoption in the research infrastructures sector
we have to move to an rm oriented approach for three reasons firstly so that we can achieve interoperability within
and between different infrastructures secondly because there are multiple players and stakeholders in the sector that have to work together
and talk to one another and thirdly so that the sector can achieve the economies of scale within and across
infrastructures that we need for attracting the attention of industry there is role for bespoke design and development due to
the unique attributes of individual infrastructures but wherever possible off the shelf capabilities should be adopted first we can do
this more easily when we have commonly accepted conceptual foundation upon which to base procurement achieving shift in culture and
mind set of the community is significant issue to be overcome it needs to balance the costs of replacing existing
technology and the consequent impact on working practices with the long term costs of support and maintenance see section problems
to be overcome complexity rms are systems modelling way of thinking that draws together all the conceptual elements and relationships
in large class of very complex distributed systems systems thinking gives us means to cope with that complexity it helps
us to better deal with change in the scientific business leading to more agile styles of thinking and response understanding
relationships between the various parts of research infrastructure helps us to understand the possible collective emergent behaviours of the infrastructure
and to practically engineer and manage real systems thus and according to apg reference model is really framework from which
portfolio of services can be derived complexity can be off putting hardisty has suggested ways to engage with rms for
the first time and how particularly to get the best out of the envri rm124 forbes article on enterprise architecture
bloomberg also offers several suggestions that are transferable to the present context you don have to take reference models too
literally you don have to do all of the rm to benefit from it just pick and choose what works
for you it basically toolkit you can use it in several different ways to baseline what you already have and
to clean up to target desired outcomes and plan out how to achieve them or in combination to deal with
troublesome area pain point first by baselining it then by targeting it and then iterating until the pain has gone
away problems to be overcome tooling and skills development effective software systems engineering depends on having robust and capable integrated
development environment ide within which all the processes of software design implementation and test can take place as noted above
industry standard design tools are beginning to support the necessary concepts but their penetration and use in research infrastructures sector
is still quite low the level of architecting skills to be found among practitioners in research infrastructures is also quite
low this has to be addressed by targeted recruiting and specialised training use of rms in other sectors rms have
been used widely in the telecoms healthcare and defence sectors as well as among architects of enterprise and public sector
systems all these sectors are characterised by their need for infrastructure at scale they involve multiple vendors who have to
work if not together then to common framework of principles and concepts to bring about widespread interoperability it easy to
make phone call to more or less anywhere on the planet or to receive streaming video there that is the
result of using reference models and standardising interfaces between sub systems and components from different vendors one view of reference
models particularly expressed by practitioners at armstrong process group apg is that they are supporting capability in the enterprise architecture
value chain putting that into the envri context is to say that rms have relevance to and use for understanding
and analysing the environmental science enterprise prior to and as part of planning and implementing engineering research infrastructures during the
esfri cluster projects covering the biomedical sciences biomedbridges physics crisp social science and humanities dasish and environmental sciences envri came
together to identify common challenges in data management sharing and integration across scientific disciplines field reference models were identified as
common interest of all the clusters subsequently rms were ranked as one of the top three issues needing to be
addressed jointly across all ris at the european level uml4odp and tooling for software systems engineering recently revised uml4odp iso
iec allows systems architects to express their systems architecture designs in graphical and standard manner using uml notation this is
exciting because it means for example that the envri rm and all its concepts can be built into software engineering
ides127 with all that implies for inheritance compliance with agreements and standards etc this makes it possible for industry standard
model based systems engineering tools such as sparx systems enterprise architect128 ibm rational software architect129 or magicdraw130 to deal with
odp based designs and thus to inherit concepts from an rm once that rm is encoded as uml4odp representation131 this
has been explored for example in the healthcare context by lopez however as far as we know there are no
open source ide tools specifically supporting uml4odp at this time eclipse132 has general support for uml but not specifically for
uml4odp on the other hand the odp and envri reference models can also be represented as an ontology see section
expressed for example in owl and rdf which means it can then be used in knowledge base over which reasoning
can take place this has multiple applications supporting the european open science cloud eosc early in april high level expert
group reported its strategic advice on the future european open science cloud eosc to the european commission by mapping the
route to european open science cloud says expert group member paul ayris the group ultimate goal is to create trusted
environment for hosting and processing research data to support world leading eu science cloud computing can change the way that
research in europe is done the creation of an open science commons would allow european researchers to collaborate share and
innovate using shared infrastructures tools and content eosc134 is envisioned as federated environment made up of contributions from many stakeholders
at both national and institutional levels the desire for minimal international guidance and governance combined with maximum freedom of implementation
means that moving towards some kind of framework of reference as the basis of the open science commons135 is inevitable
robust standards for exchanging information between different heterogeneous parts of the federated cloud environment will be paramount developing these in
an open and transparent manner will be difficult and costlier without framework of reference such as the envri reference model
within which to situate them the envri rm can be used for describing the eosc on one level there is
an implied assumption that cloud computing as understood in common parlance is the basis of the eosc this is technology
assumption and therefore also partially an engineering assumption however the true scope of eosc has to be thought of in
terms much wider than just technology and engineering especially as the former is subject to rapid evolution consideration has to
be given to the business of the eosc to the data and information it is expected to handle and to
the nature of the computation in its widest sense to be applied in order to create the trusted environment for
hosting and processing eosc implies more than is just meant by the term cloud as often used in common parlance
to mean cloud computing eosc bundles financial and business models that are science viewpoint data and information to be handled
that are information viewpoint shared provisioning operations management and systems support that is organisational and involves multiple viewpoints hardware level
protection regime involving engineering and technology viewpoints whole open ended set of ways of building and deploying executable machine images
which has computational engineering and technology range of ways of allocating resources and scheduling work again computational engineering and technology
viewpoints variety of aaai strategies and variety of collaboration and isolation regimes eosc will not be single platform or single
technology but heterogeneous collection of virtual and dynamic configurations responding to the circumstances of the moment initiatives such as kubernetes136
for example and our own envri linking model are exploring ways of developing smart mappings to cope with this cloud
is not easy certainly if you re doing most of the things the ris are expected to be doing for
them using methods with the envri rm to unpick the elements that make up cloud might be useful alignment to
research data alliance rda by engaging the scientific communities to address the issues such as data identification and citation discovery
access sharing etc the research data alliance rda has role to further promote the maturation and adoption of practices for
open research data and open science one product of rda thus far is the results from its data foundation and
terminology working group dft wg rda this is set of core terms for classifying data objects and repositories and model
of relationships between the terms these dft core terms correspond more or less with some main concepts in the information
viewpoint of the envri rm but the scope is limited to that part of the envisaged evolution of the envri
rm during the envriplus project will involve rda alignment in general terms the digital transformation agenda encompassing cloud infrastructure continuous
delivery of it services devops agile software development etc acts as significant driver bots services apis and apps this is
catch all for the general trend in consumer computing towards world of smart applications interacting with services both bot and
human via range of apis knowing all the apis where they are and how they relate to one another in
terms of compatibility and composition potential will be crucial development to watch as it spills over from mainstream consumer computing
into enterprise and academic research sectors to what extent do current rms overtly accommodate this trend to what extent do
ris realise the impact it will have for them one possible argument is that it just engineering and that all
the logical stuff is already provided for wider uptake and dependence on rms for design planning and change management becomes
apparent design patterns based on widely accepted conceptual understanding of the archetypical architecture of research infrastructures become more prominent architectures
become agile and dynamic requiring continuous re appraisal and evolution of rms to suit new circumstances relationships with requirements and
use cases tc_16 description of national marine biodiversity data archive centre138 seeks to integrate the dassh data archive centre139 with
other european marine biological data data curated by emso seadatanet jerico and embrc as joint contribution to emodnet biology the
copernicus provider this is typical test case for the envri reference model using the envri reference model rm ic_12 implementation
of envri plus rm for eufar and lter138 seeks to describe two ris with in part very different framework requirements
eufar european facility for airborne research is an emerging ri to coordinate the operation of instrumented aircraft and remote sensing
instruments for airborne research in environmental and geo sciences lter long term ecosystem research is global effort aiming at providing
information on ecosystem functioning and processes as well as related drivers and pressures on ecosystem scale watershed number of other
use cases138 for example sc_3 tc_2 tc_4 ic_3 would probably also benefit from applying rm thinking and concepts in their
analysis and design each of these use cases contains one or more detailed scenario descriptions and explanations that could benefit
from being thought about from the different viewpoints of science the business information and computation ultimately engineering and technology aspects
also become important issues and implications reference models rm and the envri rm in particular have significant role to play
in fostering the use of common language and understanding in the architectural design of environmental research infrastructures adoption and use
contributes significantly towards the goal of interoperability among research infrastructures however there are social barriers to be overcome these have
to be addressed by marketing education and training lack of training is key issue and with it the lack of
skilled architects rms have been ranked by the first round of esfri research infrastructure cluster projects as one of the
top three issues needing to be addressed jointly across all ris at the european level further discussion of the reference
model technologies can be found in section this takes longer term perspective and considers relations with strategic issues and other
technology topics technologies for providing compute storage and network resources yin chen egi alex hardisty cardiff university cu introduction context
and scope what are infrastructures the infrastructure reflection group irg irg white paper defines them to include access to high
performance computing and high throughput computing access to high end storage for ever increasing data sets advanced networking services to
connect computing and storage resources to users and instruments middleware components to enable the seamless use of the above services
including authentication and authorisation and generic services for research providing support for research workflows using combinations of the above sometimes
called virtual laboratories or virtual research environments in particular it envisions infrastructures where the principles of global collaboration and shared
resources are intended to encompass the sharing needs of all research activities the european strategy forum on research infrastructures esfri
presented the european roadmap140 for new large scale research infrastructures these are modelled as layered hardware and software systems that
support sharing of wide spectrum of resources spanning from instruments and observations through networks storage computing resources and system level
middleware software to structured information within collections archives and databases the roadmap recognises that the special needs of research infrastructures
should be met by infrastructures environmental and earth sciences have been supported by national and institutional investments for great many
years these have led to diversity of significant computing resources and support services that are the precursors of today pan
european infrastructure they now coexist with and participate in today pan european infrastructures the contemporary supported strategies lead to the
development of infrastructures in europe connecting them into continent wide infrastructures this is to allow researchers from different countries to
work together using shared resources including computers data and storage important pan european large scale infrastructures include egi eudat prace
geant openaire and helix nebula each has own focused areas egi provides pan european federated computing and storage resources prace
federates pan european high performance computing hpc resources eudat focuses on providing services and technology to support the life cycle
of data geant is the pan european data network for the research and education community interconnecting national research and education
networks nrens across europe openaire is network of open access repositories archives and journals that support open access policies the
helix nebula initiative is providing public private partnership by which innovative cloud service companies can work with major it companies
and public research organisations these infrastructures provide generic it resources and services solutions to support multiple european scientific research activities
the benefits to adopt and make good use of these resources for scientific community and research infrastructure include having ready
to use compute and storage resources and services solutions for scientific collaborations avoiding duplicated development and effort enlarged community network
and user bases since these pan european infrastructures have already been attracting many international collaborations and users sharing state of
art experience by research communities already using the infrastructure this section gives an overview of current infrastructure for european research
along with some of the forthcoming developments and innovations the focus is on pan european scale infrastructure broadly classified into
high throughput computing htc or cloud egi high performance computing hpc prace open access publications repositories and catalogues pubs openaire
and data storage and services data the eudat cdi the figure also includes social dimension characterising interactions by expert groups
the focus reflects the pan european scale of the research infrastructures ri represented in envriplus figure classifying european infrastructures in
general all of the current european scale infrastructures seek to include partners in all european member states thereby providing one
stop shop for continental scale interactions while at the same time providing access to local and regional activities in the
individual member states at european level the infrastructure is often presented in terms of computer networking high capacity computing and
high throughput computing data storage and management user tools virtual research communities and virtual research environments in the sections that
follow we focus on the first three of these sources of state of the art technology information used the technology
information is provided by infrastructure providers including egi eu and csc representative of eudat information also refers to esfri strategy
report on research infrastructure roadmap esfri short term analysis of state of the art and trends networking geant the model
for research and education networking in europe is of single national entity per country the national research and education network
nren connecting to common pan european backbone infrastructure geant in combination these networks provide powerful tool for international collaborative research
projects particularly those with demanding data transport requirements nrens141 are able to connect individual sites universities research centres other related
not for profit institutions to their high bandwidth infrastructures or arrange point to point services for bilateral collaborations geant provides
single point of contact to coordinate the design implementation and management of network solutions across the nren and geant domains
in addition to its pan european reach the geant network has extensive links to networks in other world regions including
north america latin america the caribbean north africa and the middle east southern and eastern africa the south caucasus central
asia and the asia pacific region in addition there is on going work to connect to western and central africa142
the geant network like the majority of nrens has hybrid structure operating dark fibre network and transmission equipment wherever possible
and leasing wavelengths from local suppliers in more challenging regions this structure allows the operation of both ip and point
to point services on common footprint since geant has migrated to new generation of both transmission and routing equipment platforms
the resulting network is seen as significant increase in the bandwidth available along with an improved range of network services
geant pre provisioned capacity on each of the core network trunks covering western and central europe is around 500gbps and
an advanced routing switching platform delivers ip vpn and point to point services with greater flexibility to all european nrens
the geant project provides more than just physical network infrastructure its service development and research activities address directly the needs
of the research and education community both by providing advanced international services on the nren and geant backbones and also
by developing software and middleware to target network related issues from campus to global environments the geant backbone currently offers
geant ip high quality ip service providing robustness and high levels of availability high bandwidth and global reach geant plus
point to point services offering guaranteed routing latency and stability on the full geant footprint geant lambda offering guaranteed capacity
of 10gbps or 100gbps on dedicated wavelengths over the geant operated optical fibre vpn virtual private network services which can
provide bespoke network architectures for multi site collaborations services under development in geant include143 software defined networking to facilitate faster
and easier network configuration authentication and authorisation aai services designed to address international multi domain environments centrally procured cloud service
to leverage economies of scale across the european nren constituency computing prace prace144 provides high end computing resources to european
top science the largest prace systems are generally referred to as tier these systems are in general significantly larger than
other european computer systems accessible to researchers the resources are accessible to applicants based on twice yearly calls for proposals
preparatory access proposals allowing users to develop software or test out novel ideas are also accepted over series of implementation
projects including pre commercial procurement prace include range of activities that are interesting for the biological and medical science communities
training courses software development hpc technology tracking and access to prototype resources the fourth implementation project prace 4ip is working
now towards transition to prace strengthening the internationally recognised prace brand preparing strategies and best practices towards exascale computing coordinating
and enhancing the operation of the multi tier hpc systems and services and supporting and educating users to exploit massively
parallel systems and novel architectures it is important to note that the explosion in the data generation capacity of scientific
equipment and sensors is creating new class of researchers who have different demands in terms of their use of high
performance computing hpc power and of how and where their data is stored traditionally researchers need prace and other similar
supercomputing capability capacity to execute large scale compute costly software codes for modelling and simulations it is often the case
that input data needed by these codes is moved staged to the hpc facility it may even be semi permanently
kept there the output results are either also kept there or are staged back to the researcher results are often
used multiple times to compare with other results and models so that they don have to be re generated in
contrast the new type of users wants to process and analyse their data that is too massive voluminous to be
staged this introduces new problems around locating hpc close to well founded repositories where data should be kept finding the
balance between optimal hpc location moving execution towards the data costs of data staging and changes in community working practices
around data deposition is where the challenges lie see also additional explanation about positioning eudat below in section egi the
egi infrastructure is publicly funded infrastructure giving scientists access to more than logical cpus pb of storage capacity to drive
research and innovation in europe resources are provided by about resource centres distributed across countries in europe the asia pacific
region canada and latin america egi also federates publicly funded cloud providers across europe for the implementation of an european
data cloud to support open science egi supports computing including closely coupled parallel computing normally associated with hpc compute workload
management services data access and transfer data catalogues storage resource management and other core services such as user authentication authorisation
and information discovery that enable other activities to flourish user communities gain access to egi services by partnering with egi
either directly through federating their own resource centres or indirectly by accessing national or regional resource centres that already support
their communities existing high level services federated iaas cloud run compute or data intensive tasks and host online services in
virtual machines or docker containers on it resources accessible via uniform interface store retrieve research data at multiple distributed storage
service providers share applications tools and software for data processing and analysis high throughput data analysis run compute intensive tasks
for producing and analysing large datasets and store retrieve research data efficiently across multiple service providers federated access to computing
and data manage service access and operations from heterogeneous distributed infrastructures and integrate resources from multiple independent providers with technologies
processes and expertise offered by egi consultancy for user driven innovation expertise to assess research computing needs and provide tailored
solutions for advanced computing high level services under development open data platform store and discover research data publish with open
or controlled access access and reuse data with the egi computing services accelerated computing run computational tasks on specialised processors
accelerators with traditional cpus from multiple providers allowing for faster real world execution times community specific tools to provide access
to specialised tools for data analysis contributed by the community project positioning with respect to related initiatives eudat2020 egi enables
reuse of research data available from their services prace egi complements prace hpc services with cloud and htc capabilities altogether
addressing the different computing needs of the research community geant egi relies on connectivity for distributed access to data and
computing openaire use of dissemination discovery services for research outputs supported by egi vre projects egi provides hosting environments for
services developed by vre projects and co creates community specific tools on going project such as indigo datacloud and aarc
egi adopt their software and technical solutions egi matured its portfolio of solutions that help accelerate data intensive research the
most relevant developments in egi for envriplus are launch of egi federated cloud egi opened the egi federated cloud as
production infrastructure in may based on open standards it is an interconnected grid of institutional clouds offering unprecedented versatility and
cloud services tailored for european researchers with the egi federated cloud researchers and research communities can deploy scientific applications and
tools onto remote servers in the form of virtual machine images store files complete file systems or databases on remote
servers use compute and storage resources elastically based on dynamic needs scale up and down on demand immediately address workloads
interactively no more waiting time as with grid batch jobs access resource capacity in institutional clouds146 connect their own clouds
into european network to integrate and share capacity or build their own federated cloud with the open standards and technologies
used by the egi federated cloud since its launch the egi federated cloud has attracted more than use cases from
various scientific projects research teams and communities among these there are several applications from environmental sciences simplifying access to egi
for the long tail of science while processes to gain access to egi are well established across the ngis national
grid initiatives for entire user communities individual researchers and small research teams sometimes struggle to access compute and storage resources
for the implementation of their applications recognising the need for simpler and harmonised access for individual researchers and small research
groups long tail of science the egi community has launched december prototype platform147 providing integrated services from the ngis to
those researchers and small research teams who work with data but have limited or no expertise in using distributed systems
the platform lowers the barrier to access grid and cloud infrastructure via centrally operated access management portal and an open
set of virtual research environments designed for the most frequent use cases the project defines security policies and implements new
security services that enable personalised secure and yet simple access to infrastructure resources via the virtual research environments for individual
users the platform authenticates users via the edugain federation and other username password based mechanisms complementing the long established certificate
based access mechanisms egi engage one of the main objectives of the horizon funded egi engage project 7m is to
expand the capabilities of egi cloud and data services and the spectrum of its user base by engaging with large
research infrastructures ris the long tail of science and with industry smes small and medium sized enterprises the key engagement
instrument for this is network of eight competence centres in which national grid initiatives ngis user communities technology and service
providers work together to collect requirements integrate community specific applications into state of the art services foster interoperability across infrastructures
and evolve services through user centric development model the competence centres provide state of the art services training technical user
support and application co development to specific scientific domains the following science communities including from environmental sciences have dedicated competence
centres in egi engage earth science research epos eiscat 3d life science research elixir biodiversity and ecosystem research lifewatch biobanking
and medical research biobanking and bimolecular research infrastructure bbmri eric structural biology and brain imaging research mobrain supporting wenmr and
integrating structural biology instruct arts and humanity dariah disastermitigation the helix nebula marketplace the helix nebula initiative is public private
partnership by which innovative cloud service companies can work with major it companies and public research organisations the helix nebula
marketplace hnx is the first multi vendor product of the initiative delivering easy and large scale access to range of
commercial cloud services through an innovative open source broker technology series of cloud service procurement actions including joint pre commercial
procurement co funded by the european commission are using the hybrid public private cloud model to federate infrastructures with commercial
cloud services into common platform delivering services on pay per use basis data research data eudat services eudat is pan
european data infrastructure initiative in consortium of partners including research communities national data and high performance computing hpc centres technology
providers and funding agencies from countries eudat aims to build sustainable cross disciplinary and cross national data infrastructure that provides
set of shared services for accessing and preserving research data the eudat collaborative data infrastructure cdi is defined data model
and set of technical standards and policies adopted by european research data centres and community data repositories to create single
european infrastructure of interoperable data services the eudat cdi is realised through ongoing collaboration between service providers and research communities
working as part of common framework for developing and operating an interoperable layer of common data services the scope of
the cdi covers data management functions and policies for upload and retrieval identification and description movement replication and data integrity
eudat vision is to enable european researchers and practitioners from any research discipline to preserve find access and process data
in trusted environment the cdi is conceived as network of collaborating cooperating centres combining the richness of numerous community specific
data repositories with the permanence and persistence of some of europe largest scientific data centres at the heart of the
cdi is network of distributed storage systems hosted at the major scientific data centres between them these centres manage more
than pb of high performance online disk in support of european research plus greater amount of near line tape storage
eudat strength lies in the connections between these centres the resilience resulting from the geographically distributed network and its ability
to store research data right alongside some of the most powerful supercomputers in europe currently eudat is working with more
than research communities covering wide range of scientific disciplines and has built suite of integrated services table below to assist
them in resolving their technical and scientific challenges covering both access and deposit from informal data sharing to long term
archiving and addressing identification discoverability and computability of both long tail and big data eudat services aim to address the
full lifecycle of research data table the eudat service catalogue service function status individual researcher ri community manager service provider
data discovery b2find multi disciplinary joint md catalogue active metadata catalogue md extraction md store index under develop data hosting
registration management sharing b2drop cloud storage sync exchange active b2safe policy driven data management active b2share repository for sharable digital
objects active b2handle policy based prefix pid management active data type registry under develop data access interface movement b2access federated
multi protocol iam active generic api common data interface service under develop b2stage data staging service cdi ext active subscription
data transfer subscription under develop consultancy training on services data management active consultancy on licensing certification data privacy data system
design active helpdesk support and enabling active operations service hosting paas iaas saas under develop monitoring availability reliability monitoring active
accounting storage data usage reporting under develop slc management service portfolio catalogue active coordination project implementation service resource provisioning active
site registry site service service groups active these services have been developed together with research communities coming mostly from the
environmental sciences epos icos eiscat enes lter drihm life sciences elixir vph bbmri ecrin dixa and social sciences and humanities
clarin cessda dariah in october eudat issued public call for data pilot projects and received applications including from earth and
environmental sciences energy and environment disciplines from the biomedical and life sciences from the social sciences and humanities and from
physical sciences and engineering altogether these pilots represent potential user base of researchers eudat distinguishes three main types if users
customers of its services and infrastructure individual researchers those wishing to share data with colleagues or collaborators or those wishing
to discover and re use data as part of their on going research these users are anybody researchers from academia
and industry citizen scientists policy makers and members of the public anyone wanting to share or re use european research
data in simple powerful ways as user your main responsibility is to adhere to the terms and conditions of the
b2 services provided by the eudat consortium organized research communities those concerned with the management of their research infrastructure and
or community specific data repositories who wish to join their repositories formally with the cdi network or deploy eudat services
on top these research communities are organized research groups ec projects research infrastructures esfri or universities and libraries anyone interested
in archiving replicating processing and cataloguing data on behalf of the research community they support they either use eudat services
as they are according to the service terms and conditions through an agreement with specific service provider or by joining
the cdi as node service provider cdi service providers service providers wish to use and or deploy cdi services to
support or augment their existing role and service portfolio to provide long term preservation of important digital assets offer wider
accessibility intelligent caching of data near compute data integrity checking and so on positioning eudat in defining the eudat cdi
position with respect to other infrastructure initiatives and organisations eudat regards any and all infrastructures including though not limited to
prace egi helixnebula openaire as organisational end users of eudat services the cdi gateway api defines clear contract with external
end users and consequently set of stable targets for computational jobs scripts programs or workflows running on external infrastructure the
key value that eudat implementation of the cdi brings to any external user is well defined api to eudat services
and coherent service offerings across all eudat partner sites these common coherent service interfaces create the line of demarcation between
the eudat cdi and the other infrastructures the boundary of the domain of registered data other infrastructures then have clear
ways to interact with the eudat cdi across the network they can retrieve metadata records by pid htc workflows hpc
programs publication repositories catalogues retrieve open access data by pid htc workflows hpc programs publication repositories catalogues subscribe to metadata
feeds using oai pmh publication catalogues where authorised create upload data metadata and receive registered pid htc workflows hpc programs
scripts where authorised update or delete data and or metadata by pid htc workflows hpc scripts this model positions the
eudat cdi as the home for persistent shared re used research data eudat is about preserving research data for reuse
and an aspect of making digital data reusable lies in providing the capabilities for efficient computation on them eudat2020 enables
data analytics by staging data to dedicated analysis systems leveraging the computing capacity made available via egi and prace eudat
has issued two joint public calls in with prace allowing prace users which have been granted prace computing resources to
store the data resulting from simulations into eudat it is also working with egi to strengthen interoperability between the two
infrastructures with view to connect data stored in the eudat collaborative data infrastructure to high throughput and cloud computing resources
provided by egi eudat develops solutions for data coupled computing including big data frameworks and workflow systems for initiating computing
tasks on datasets located in the eudat infrastructure eudat b2stage library allows to stage data to hpc computing environments and
is being developed further to add support for hadoop and spark big data systems eudat also offers hosting environment for
the deployment and provision of data analytics services directly at the data centres building on the service hosting framework successfully
trialled in the first eudat project to provide flexible virtual computing environment at participating data centres highly configurable cluster computing
platform sited right alongside the data archives publications data and openaire openaire149 enables researchers to deposit research publications and data
into open access repositories and provides support to researchers at the national institutional and local level to guide them on
how to publish in open access oa and how to manage the long tail of science data within the institution
environment this complements national initiatives in several european countries if researchers have no access to an institutional national or subject
repository zenodo150 hosted by cern enables them to deposit their articles research data and software zenodo exposes its contents to
openaire and offers range of access policies helping researchers to comply with the open access demands from the ec and
the erc european research council it now uses cerif for its metadata zenodo has also been extended with important features
that improve data sharing such as the creation of persistent identifiers for articles research data and software openaire has recently
moved from dc like metadata catalogue to cerif in openaireplus open science commons of egi egi developed its open science
commons vision151 inspired by the emerging open access policy in the european research area the goal of open access is
to ensure that research results are made freely available to end users and that they are reusable research results and
resources thus become shared community resource commons in order for this to happen researchers need to change their own behaviours
and they need to be supported with services that simplify the sharing of research results their discovery and reuse in
the egi engage project egi is developing the concept of federated open research data platform an innovative solution enabling to
publish data link to open access repositories and offering easy integration into processing capabilities egi federated cloud furthermore the federated
cloud infrastructure including existing publicly funded institutional cloud and expanding to commercial clouds will evolve to offer iaas paas and
saas for specific communities the long tail of research and the industrial sme sector in collaboration with other infrastructures services
will be tailored to meet the needs of the long tail of research and their evolution will be driven by
the requirements of the ris on the esfri roadmap that participate in the egi engage project through competence centres research
data alliance together and with many other organisations the pan european infrastructure initiatives are contributing to international cooperation in addressing
issues around large scale data infrastructures through the recently formed international research data alliance rda launched as community driven organization
in by the european commission the united states national science foundation and national institute of standards and technology and the
australian government department of innovation the research data alliance rda has the goal of building the social and technical infrastructure
to enable open sharing of data with close to members from countries april rda provides neutral space where its members
can come together through focused global working and interest groups to develop and adopt infrastructure that promotes data sharing and
data driven research and accelerate the growth of cohesive data community that integrates contributors across domain research national geographical and
generational boundaries in europe the work of the rda has been supported by several projects funded under fp7 and h2020
longer term horizon the recent revised esfri roadmap esfri highlights the notion of european infrastructure commons referring to the framework
for an easy and cost effective shared use of distributed electronic resources for research and innovation across europe and beyond
the concept is outlined by the infrastructure reflection group irg based on the identification of the need for more coherent
infrastructure landscape in europe according to the irg report153 an essential feature of the commons is the provisioning of clearly
defined comprehensive interoperable and sustained set of services provisioned by several infrastructure providers both public and commercial to fulfil specific
needs of the users this set should be constantly evolving to adapt to changing user needs complete in the sense
that the needs of all relevant user communities are served and minimal in the sense that all services are explicitly
motivated by user needs and that any overlap of services are thoroughly motivated the commons has three distinct elements platform
for coordination of the services building the commons with central role for european research innovation and research infrastructure communities provisioning
of sustainable and interoperable infra structure services within the commons promoting flexible and open approach where user communities are empowered
to select the services that fulfill their requirements implementation of innovation projects providing the constant evolution of infrastructures needed to
meet the rapidly evolving needs of user communities in summary the ultimate vision of the commons is to reach integration
and interoperability in the area of infrastructure services within and between member states and on the european level and globally
this infrastructure commons is also solid basis for building the european open science cloud as introduced in the description of
the digital single market com final swd final already containing most of the ingredients needed for an integrated european platform
for open science esfri to support this vision it would request long term agenda for supporting coherent innovative and strategic
european infrastructure policy making and the development of convergent and sustainable infrastructure services today april the ec announces the european
cloud initiative154 7billion of public and private investment in european open science cloud opening up by default all scientific data
flagship initiative on quantum technology development and deployment of european high performance computing data storage and network infrastructure including by
acquiring two prototype next generation supercomputers of which one would rank among the top three in the world establishing european
big data centre and upgrading the backbone network for research and innovation geant relationships with requirements and use cases envriplus
has already been collaborating with these pan european infrastructures such as egi and eudat eudat services are chosen by some
of research infrastructures for data management other ris will benefit from feedback on their initial experiences in envriplus wp9 egi
will provide computing and storage resources for deploying services developed by envriplus development wps the task begins with identifying number
of community use cases and the feasibility of deployments of the use cases are evaluated by infrastructure experts use cases
are selected which will have resources and technical supports from egi for deployments issues and implications interoperable access to these
infrastructures remains as challenging issue in this sense envriplus is in good position to provide real use cases requirements to
influence the future implementations of these infrastructures further discussion of the provision of computational storage network and software technologies can
be found in section this takes longer term perspective and considers relations with strategic issues and other technology topics assessment
of achievements gaps and impact this section assesses the achievements in the two parts requirements gathering and technology review and
their relationships it also assesses the work implications for the planned work and for additional actions finally it categorises the
outcomes in terms of their short term and longer term implications assessment of requirements gathering the requirements gathering campaign built
on the understanding developed during the preceding envri project and on the intensive discussions that shaped the envriplus bid its
primary purpose was to sufficiently understand the combined requirements of the ris many of which are new since envri and
all of which have developed substantially to be sure that the work undertaken in theme is the best possible match
to the current and anticipated requirements there were the following subsidiary purposes to stimulate dialogue and effective communication within envriplus
particularly between experts in ris with ict experts to initiate resource for recording and analysing requirements that will be sustained
and useful throughout the project and beyond to help with awareness raising and training by identifying where emphasis should be
placed at this time undertaking requirements gathering process near the start of project is necessary if it is to guide
subsequent investment however it then meets an extra difficulty as many partners and individuals are new and are orienting themselves
and building their own communication and decision making networks this was experienced and led to some delays it also meant
that some of the outcomes are not as authoritative and based on as extensive analysis as we might have hoped
therefore they should be checked before significant investments are undertaken nevertheless they are significant and valuable achievement that meets the
primary goal and that makes substantial contribution to all three subsidiary purposes the gathered requirements and the requirement gathering process
are complementary to the use case activity55 that is also underway in envriplus the agile co design and co development
undertaken for each use case will deepen and refine both requirements and technology review for their focused areas the use
cases will also develop and extend the communication paths helping build stronger asset powering collaboration the first subsidiary goal the
contributions to the three subsidiary purposes will be reviewed first we then present an analysis of how well the primary
goal was met fostering communication the intensive discussions between go betweens and ri representatives formed many new interpersonal bridges this
was frequently new connection and they have good potential for sustained value throughout the envriplus project and beyond although very
little staff time was formally allocated to this activity in many of the ris that initial communication frequently triggered further
communication within the ri and among those who will undertake theme tasks in most cases the topic leader will also
be leading the subsequent related task and they used this as an opportunity to start communications within their planned team
foundation for requirements refinement this report has been derived from the wiki pages where the primary information about requirements were
gathered155 this initial collection is already an asset for those planning implementation tasks and for those wanting to know how
other ris are addressing data challenges it will provide an easily searched and easily updated framework as the understanding of
requirements progresses this should prove valuable even beyond the end of envriplus provided the material is kept up to date
awareness raising and training the requirements gathering particularly the investigation of general issues and the analysis of community support needs
has identified areas where these needs are evident and relatively urgent the differences between ris responses reveal more opportunities for
developing these aspects of envriplus this sets the scene for the analysis of the primary goal validation of envriplus data
oriented ict in general terms every one of the planned lines of development were endorsed by the requirements gathering and
no major omissions have been identified however more detailed review does reveal some significant issues which will be introduced below
and collated in sections and these will be pursued by first considering the overall process in conjunction with the general
requirements gathering section below and then considered under the topic headings identification and citation curation cataloguing processing provenance optimisation and
community support sections below these headings correspond to areas where significant effort will be invested in envriplus they are also
informed by the reference model29 developed in envri and being further developed in envriplus process and general requirements the detailed
process was described in section on page it ran as planned but it is worth reviewing its progress in terms
of table on page there it will be seen that there is substantial variability by ri and similar variability by
topic for every ri significant effort was made to develop communication and obtain information about requirements for all relevant topics
in some cases particularly strong relationship or existing knowledge enabled complete coverage in some the ri was mature in the
sense that the ri or those involved in the work had been active in the particular domain for significant number
of years the marine ris that are already sharing data such as euro argo and seadatanet are good examples such
maturity leads to an appreciation of the complexities and significance of various requirements in other cases the ri concerned was
in consortium of interacting often global related communities that share data and hence appreciate many of the issues epos is
one example for such ris it was possible to gather good input on virtually every topic for all of the
ris contact was made and information was gathered for at least the general requirements in some cases an ri deemed
their interests were already covered by another ri known to be similar with which they worked closely the variation between
topics is also manifestation of maturity variation but this time combined with variations in the parts of the data lifecycle
in which each ri is involved as shown in table the topics such as identification and citation cataloguing and processing
are encountered at the early stages of developing an ri work and at the early stages of the data lifecycle
whereas the value of curation and provenance become much more apparent after running data gathering and sharing campaign for long
periods or from being involved in the later stages of the data lifecycle optimisation is an extreme example of this
effect only when production and diverse users are demanding more resources than an ri can afford does optimisation become priority
before that the focus is on delivering the breadth of functionality users require and gaining adoption as we shall explain
below section these can be met by addressing different aspects of optimisation the outcome of gathering general requirements is analysed
in section and summarised in series of tables these provide summary of the information uncovered via each group of general
questions however readers are referred to the relevant part of the wiki for all details156 the overall conclusion wold be
that there are many opportunities for benefit from sharing ideas methods and technologies between ris that there is much potential
for using their data in combination and that there is general need for awareness raising and training however these high
level consistencies have to be treated with great care there are many lower level details where differences are significant future
work will need to tease out which of those differences are fundamentally important and which are coincidental results from the
path the participants have taken to date fundamental differences need recognition and support with well developed methods for linking across
them founded on scientific insights the unforeseen differences may in time be overcome by incremental alignment however great care must
be taken to avoid unnecessary disruption to working practices and functioning systems this will require deeper investigation through appropriate use
cases and agile investigations157 identification and citation requirements assessment the identification and citation requirements are summarised in section which validates
the need for this provision in envriplus however the ris showed significant diversity in their data identification and data citation
practices and many were not aware of their importance in supporting data use data identification and citation are however key
to reproducibility and quality in data driven science and very often vital in persuading data creators of the value of
contributing their data data users of the need to recognise that contribution and funders to continue to support data gathering
and curation the next steps will include envriplus will consider programme of awareness raising and practical training to alert those
ris that would benefit and to raise the skills of practitioners in any ri of the relevance of data citation
and identification issues and some of the available technologies that will help with solutions and rapid adoption of good practices
the eu edison project158 has already worked on this for the cluster project corbel for the bio medical ris the
conceptual and technical issues in data citation and identification are strongly linked with best practice in curation and practically linked
with cataloguing and provenance these will be considered together in order to provide consistent advice and solutions to ris key
issue is adoption of appropriate steps in working practices where these are exploratory or innovative the citation of underpinning data
may be crucial to others verifying the validity of the approach and to later packaging for repeated application once working
practice is established it should be formalised as workflow and packaged through good user interfaces so that as much of
the underpinning record keeping citation cataloguing and provenance is automated this has two positive effects it enables the practitioners to
focus on domain specific issues without distracting record keeping chores and it promotes consistent solution to be incrementally refined for
these things to happen there have to be good technologies services and tools supporting each part of these processes data
citations being automatically and correctly generated as suggested by buneman et al buneman similarly constructing immediate payoffs for practitioners using
citation as suggested by myers et al myers will increase the chances of researchers engaging with identification at an earlier
stage many researchers today access and therefore consider citing individual files this poses problems if the identified files may be
changed the issue of fixity many research results and outputs depend on very large numbers of files and simply enumerating
them does not yield comprehensible citation many derivatives depend on computationally selected parts of the input file many accesses to
data are via time varying collections catalogues or services that may yield different results or contents on different occasions generically
referred to as databases some results will deal with continuous streaming data often citations should couple together the data sources
the queries that selected the data the times at which those queries were applied the workflows that processed these inputs
and parameters or steering actions provided by the users often during the application of the scientific method that potentially influenced
the result all of these pose more sophisticated demands on the data identification and citation systems at present they should
at least be considered during the awareness raising proposed above in due course those advanced aspects that would prove useful
to one or more of the ri communities should be further analysed and supported this is revisited in the technology
review section and in section curation requirements assessment the curation requirements validate the need for envriplus developing curation solutions but
do not converge on particular requirements see section which analyses the information supplied by seven ris who responded to this
topic see the wiki page for details159 in the planned work of envriplus this work is already conceptually and practically
interrelated with cataloguing and provenance in wp8 as remarked above it should also strongly couple with the work on data
identification and citation consequently many of the issues that emerge are similar to those identified above however some further issues
arise these are enumerated below the appreciation of the needs for curation is varied and often limited one manifestation of
this is the universal absence of data management plans160 consequently this topic again poses requirement for an envriplus programme of
awareness raising and training if that is conducted collaboratively then it will also help develop cross disciplinary alliances that will
benefit scientific outcomes management decisions and long term cost benefit trade offs the need for intellectual as well as ict
interworking between these closely related topics identification and citation curation cataloguing and provenance is already recognised their integration will need
to be well supported by tools services and processing workflows used to accomplish the scientific methods and the curation procedures
however there was negligible awareness of the need to preserve software and the contextual information necessary to re run it
with identical effects the need for this combination for reproducibility is identified by belhajjame et al with implementations automatically capturing
the context and synthesising virtual environments belhajjame as above it is vital to support the day to day working practices
and the innovation steps that occur in the context of curation with appropriate automation and tools this is critical both
to make good use of the time and effort of those performing curation and to support innovators introducing new scientific
methods with consequential curation needs the challenge of handling all forms of data described in section for identification and citation
is compounded with the need to properly capture diverse forms of software and wide variety of often distributed computational contexts
in order to fully support reproducibility curation needs to address preservation and sustainability carefully preserving key information to underwrite the
quality and reproducibility of science requires that the information remains accessible for sufficient time this is not just the technical
challenge of ensuring that the bits remain stored interpretable and accessible it is also the socio political challenge of ensuring
longevity of the information as communities and funders priorities vary this is significant step beyond archiving which is addressed in
eudat with the b2safe service161 one aspect of the approach to sustainable archiving is to form federations with others undertaking
data curation as suggested by oais162 federation arrangements are also usually necessary in order that the many curated sources of
data environmental scientists need to use are made conveniently accessible such data intensive federations dif underpin many forms of multi
disciplinary collaboration and supporting them well is key step in achieving success as each independently run data source may have
its own priorities and usage policies often imposed and modified by its funders it is essential to set up and
sustain an appropriate dif for each community of users many of the ris deliver such federations today without common framework
to help them and many of the envriplus partners are members of multiple federations these issues are revisited in sections
and they lead to recommendations in sections and cataloguing requirements assessment as for the preceding topics the analysis of requirements
see section validated the need for envriplus help with cataloguing solutions but current practice and understanding of precise needs was
once again very varied there are wide variety of items that could be catalogued from instruments and deployments at the
data acquisition stage right through every step of data processing and handling including the people and systems responsible up to
the final data products and publications made available for others to use most responding ris pick small subset of interest
but it is possible that whole network of artefacts need cataloguing to facilitate provenance and many of these would greatly
help external and new users find and understand the research material they need there is similar variation in the kinds
of information metadata provided about catalogue entries only epos has systematic approach by using cerif though many have commonalities developing
because of the inspire directive eu parliament so again we will consider few implications programme of awareness raising training and
boundary crossing events is urgently needed to help develop greater appreciation of the value of catalogues as an aid to
research163 lead to more precise requirements initiate alliances and accelerate adoption as always adoption will only happen if there is
an evident benefit to researchers critical factor that emerged in general requirements discussions was the need to easily access data
this clearly depends on good query systems that search the relevant catalogues and couple well with data handling and provenance
recording the query system is closely coupled with catalogue design and provision but it also needs integration with other parts
of the system euro argo identified particular version of data access being able to specify requirement for repeating data feed
catalogues are key element in providing convenient use of federations of resources it is probably necessary to have high level
catalogue that identifies members of the federation and the forms of interaction preferably machine to machine they support initially users
may navigate this maze and handle each federation partner differently but providing coherent view and single point of contact has
huge productivity gains it is moot point whether this requires an integrated catalogue or query systems that delegate sub queries
appropriately this is another example where effective automation can greatly improve the productivity of all the ri practitioners those that
support the systems internally and maintain quality services and those who use the products for research and decision making it
is anticipated that federations will grow incrementally and that the automation will advance to meet their growing complexity and to
deliver holistic and coherent research environment where the users enjoy enhanced productivity this will depend on catalogues holding the information
needed for that automation as well the information needed for ri management and end user research once again there may
be some merit in making the advantages of catalogues evident in the short term by coupling catalogue use with operations
that user want to perform such as having selected data via catalogue moving it or applying method to each referenced
item similarly allowing the users some free form additions and annotations to catalogue entries that help them pursue their own
goals may be helpful many of these issues are revisited in the context of the cataloguing technology review section and
their implications are considered in section processing requirements assessment once again the analysis of requirements see section validated the need
for envriplus to help with processing solutions the wide scope of potential contexts in which processing could be applied from
quality assurance close to data acquisition to transformations for result presentation and every research data management or curation step in
between makes this complex factor to consider user engagement with this topic also varies validly between two extremes those who
